<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"><title>问题小排查 - 维修区刷紫</title>
<meta property="og:title" content="问题小排查 - 维修区刷紫"><meta name=twitter:title content="问题小排查 - 维修区刷紫"><meta name=author content="金汤力"><link rel=icon type=image/x-icon href=/images/favicon.ico><meta property="og:site_name" content="维修区刷紫"><meta property="og:url" content="/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.120.2"><link href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/index.xml rel=alternate type=application/rss+xml title=维修区刷紫><link href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/index.xml rel=feed type=application/rss+xml title=维修区刷紫><script src=https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/Base64/1.3.0/base64.min.js integrity="sha512-IFxgh3q1bUsg/sL6qotMkJZTOvPyYSS6mRSSIVnJndN5j9vWcQ+oJyHkelIkRAOaKgdU1ibHJOs4HX15sPtZKw==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b5f7da576488071eb46ec9fe633fa64",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=/css/style.css media=all><link rel=stylesheet href=/css/style-dark.css media="all and (prefers-color-scheme: dark)"><link rel=stylesheet href=/css/syntax.css media=all><link rel=stylesheet href=/css/custom.css media=all><script src=/js/script.js></script><script src=/js/custom.js></script><script defer src=/fontawesome/all.min.js></script></head><body><header class=site-header><nav class=site-navi><h1 class=site-title><a href=/>维修区刷紫</a></h1><ul class=site-navi-items><li class=site-navi-item-archives><a href=/archives/ title=所有文章>所有文章</a></li><li class=site-navi-item-categories><a href=/categories/ title=类别>类别</a></li><li class=site-navi-item-about><a href=/about/ title=关于我>关于我</a></li></ul></nav></header><hr class=site-header-bottom><div class=main role=main><section class="list term-list"><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E5%85%B3%E4%BA%8Edevice-or-resource-busy%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5/ class=article-titles><h2 class=article-title>【问题小排查】关于device or Resource Busy如何排查</h2></a><ul class=article-meta><li class=article-meta-date><time>2021-07-09</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><div class=article-content>背景 在 kubernetes 环境中，可能会遇到因目录被占用导致 pod 一直 terminating:
1 Aug 27 15:52:22 VM-244-70-centos kubelet[906978]: E0827 15:52:22.816125 906978 nestedpendingoperations.go:270] Operation for "\"kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\" (\"b45f3af4-3574-472e-b263-c2b71c3b2ea0\")" failed. No retries permitted until 2021-08-27 15:54:24.816098325 +0800 CST m=+108994.575932846 (durationBeforeRetry 2m2s). Error: "UnmountVolume.TearDown failed for volume \"default-token-fltdk\" (UniqueName: \"kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\") pod \"b45f3af4-3574-472e-b263-c2b71c3b2ea0\" (UID: \"b45f3af4-3574-472e-b263-c2b71c3b2ea0\") : unlinkat /var/lib/kubelet/pods/b45f3af4-3574-472e-b263-c2b71c3b2ea0/volumes/kubernetes.io~secret/default-token-fltdk: device or resource busy" 本文记录下排查方法。
找出目录被谁占用的 看下目录哪个进程 mount 了:
1 2 $ find /proc/*/mounts -exec grep /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm {} + 2>/dev/null /proc/6076/mounts:tmpfs /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm tmpfs rw,relatime 0 0 根据找出的进程号，看看是谁干的:</div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E5%85%B3%E4%BA%8Edevice-or-resource-busy%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E9%92%88%E5%AF%B9containerd-v1.4.3%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98/ class=article-titles><h2 class=article-title>【问题小排查】针对containerd V1.4.3拉取镜像的问题</h2></a><ul class=article-meta><li class=article-meta-date><time>2021-06-11</time></li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li></ul><div class=article-content><h3 id=问题描述>问题描述</h3><p>在 containerd 运行时的 kubernetes 线上环境中，出现了镜像无法下载的情况，具体报错如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>Failed to pull image<span class=p>&amp;</span>nbsp<span class=p>;</span><span class=sb>`</span>  <span class=sb>`</span><span class=s2>&#34;ccr.ccs.tencentyun.com/tkeimages/tke-hpc-controller:v1.0.0&#34;</span><span class=sb>`</span>  <span class=sb>`</span>: rpc error: <span class=nv>code</span> <span class=o>=</span> NotFound <span class=nv>desc</span> <span class=o>=</span> failed to pull and unpack image<span class=p>&amp;</span>nbsp<span class=p>;</span><span class=sb>`</span>  <span class=sb>`</span><span class=s2>&#34;ccr.ccs.tencentyun.com/tkeimages/tke-hpc-controller:v1.0.0&#34;</span><span class=sb>`</span>  <span class=sb>`</span>: failed to unpack image on snapshotter overlayfs: failed to extract layer sha256:d72a74c56330b347f7d18b64d2effd93edd695fde25dc301d52c37efbcf4844e: failed to get reader from content store: content digest sha256:2bf487c4beaa6fa7ea6e46ec1ff50029024ebf59f628c065432a16a940792b58: not found
</span></span></code></pre></td></tr></table></div></div><p>containerd 的日志中也有相关日志：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>containerd<span class=o>[</span>136<span class=o>]</span>: <span class=nv>time</span><span class=o>=</span><span class=s2>&#34;2020-11-19T16:11:56.975489200Z&#34;</span> <span class=nv>level</span><span class=o>=</span>info <span class=nv>msg</span><span class=o>=</span><span class=s2>&#34;PullImage \&#34;redis:2.8.23\&#34;&#34;</span>
</span></span><span class=line><span class=cl>containerd<span class=o>[</span>136<span class=o>]</span>: <span class=nv>time</span><span class=o>=</span><span class=s2>&#34;2020-11-19T16:12:00.140053300Z&#34;</span> <span class=nv>level</span><span class=o>=</span>warning <span class=nv>msg</span><span class=o>=</span><span class=s2>&#34;reference for unknown type: application/octet-stream&#34;</span> <span class=nv>digest</span><span class=o>=</span><span class=s2>&#34;sha256:481995377a044d40ca3358e4203fe95eca1d58b98a1d4c2d9cec51c0c4569613&#34;</span> <span class=nv>mediatype</span><span class=o>=</span>application/octet-stream <span class=nv>size</span><span class=o>=</span><span class=m>5946</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=尝试复现>尝试复现</h3><p>分析环境信息:</p><ul><li>container v1.4.3 运行时。</li><li>基于 1.10 版本的 docker 制作的镜像（比如 dockerhub 镜像仓库中的 redis:2.8.23）。</li></ul><p>然后根据以上版本信息构造相同环境，通过如下命令拉取镜像：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ crictl pull docker.io/libraryredis:2.8.23
</span></span><span class=line><span class=cl>FATA<span class=o>[</span>0001<span class=o>]</span> pulling image failed: rpc error: <span class=nv>code</span> <span class=o>=</span> NotFound <span class=nv>desc</span> <span class=o>=</span> failed to pull and unpack image <span class=s2>&#34;docker.io/library/redis:2.8.23&#34;</span>: failed to unpack image on snapshotter overlayfs: failed to extract layer sha256:4dcab49015d47e8f300ec33400a02cebc7b54cadd09c37e49eccbc655279da90: failed to get reader from content store: content digest sha256:51f5c6a04d83efd2d45c5fd59537218924bc46705e3de6ffc8bc07b51481610b: not found
</span></span></code></pre></td></tr></table></div></div><p>问题复现，基本确认跟 containerd 版本与打包镜像的 docker 版本有关。</p></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E9%92%88%E5%AF%B9containerd-v1.4.3%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5pod%E7%8A%B6%E6%80%81%E4%B8%80%E7%9B%B4terminating/ class=article-titles><h2 class=article-title>【问题小排查】Pod状态一直Terminating</h2></a><ul class=article-meta><li class=article-meta-date><time>2021-02-11</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><div class=article-content><h2 id=need-to-kill-pod>Need to kill Pod</h2><blockquote><p>$ kubectl describe pod/apigateway-6dc48bf8b6-clcwk -n cn-staging</p><p>Normal Killing 39s (x735 over 15h) kubelet, 10.179.80.31 Killing container with id docker://apigateway:Need to kill Pod</p></blockquote><p>可能是磁盘满了，无法创建和删除 pod</p><p>处理建议是参考Kubernetes 最佳实践：<a href=https://tencentcloudcontainerteam.github.io/tke-handbook/best-practice/kubernetes-best-practice-handle-disk-full.html>处理容器数据磁盘被写满</a></p></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5pod%E7%8A%B6%E6%80%81%E4%B8%80%E7%9B%B4terminating/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E6%8E%92%E6%9F%A5-close_wait-%E5%A0%86%E7%A7%AF/ class=article-titles><h2 class=article-title>【问题小排查】排查 CLOSE_WAIT 堆积</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-10-21</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/><i class="fa-solid fa-folder"></i>
计算机网络
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>TCP 连接的 CLOSE_WAIT 状态，正常情况下是短暂的，如果出现堆积，一般说明应用有问题。</p></blockquote><h3 id=close_wait-堆积的危害>CLOSE_WAIT 堆积的危害</h3><p>每个<code>CLOSE_WAIT</code>连接会占据一个文件描述，堆积大量的<code>CLOSE_WAIT</code>可能造成文件描述符不够用，导致建连或打开文件失败，报错<code>too many open files</code>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>dial udp 9.215.0.48:9073: socket: too many open files
</span></span></code></pre></td></tr></table></div></div><h3 id=如何判断>如何判断?</h3><p>检查系统<code>CLOSE_WAIT</code>连接数:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>lsof <span class=p>|</span> grep CLOSE_WAIT <span class=p>|</span> wc -l
</span></span></code></pre></td></tr></table></div></div><p>检查指定进程<code>CLOSE_WAIT</code>连接数:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>lsof -p <span class=nv>$PID</span> <span class=p>|</span> grep CLOSE_WAIT <span class=p>|</span> wc -l
</span></span></code></pre></td></tr></table></div></div><h3 id=为什么会产生大量-close_wait>为什么会产生大量 CLOSE_WAIT?</h3><p>我们看下 TCP 四次挥手过程:</p><p><img src=/images/tcp_established.png alt=tcp_established></p></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E6%8E%92%E6%9F%A5-close_wait-%E5%A0%86%E7%A7%AF/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5service%E6%97%A0%E6%B3%95%E8%A7%A3%E6%9E%90/ class=article-titles><h2 class=article-title>【问题小排查】Service无法解析</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-09-29</time></li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li></ul><div class=article-content><h3 id=检查kube-dns或coredns服务是否正常>检查kube-dns或CoreDNS服务是否正常</h3><ol><li>kubelet 启动参数 &ndash;cluster-dns 可以看到 dns 服务的 cluster ip:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ ps -ef <span class=p>|</span> grep kubelet  
</span></span><span class=line><span class=cl>... /usr/bin/kubelet --cluster-dns<span class=o>=</span>172.16.14.217 ...
</span></span></code></pre></td></tr></table></div></div><ol start=2><li>找到 dns 的 service:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ kubectl get svc -n kube-system <span class=p>|</span> grep 172.16.14.217  
</span></span><span class=line><span class=cl>kube-dns              ClusterIP   172.16.14.217   &lt;none&gt;        53/TCP,53/UDP              47d
</span></span></code></pre></td></tr></table></div></div><ol start=3><li>看是否存在 endpoint:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ kubectl -n kube-system describe svc kube-dns <span class=p>|</span> grep -i endpoints  
</span></span><span class=line><span class=cl>Endpoints:         172.16.0.156:53,172.16.0.167:53  
</span></span><span class=line><span class=cl>Endpoints:         172.16.0.156:53,172.16.0.167:53
</span></span></code></pre></td></tr></table></div></div><ol start=4><li>检查 endpoint 的 对应 pod 是否正常:</li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ kubectl -n kube-system get pod -o wide <span class=p>|</span> grep 172.16.0.156  
</span></span><span class=line><span class=cl>kube-dns-898dbbfc6-hvwlr            3/3       Running   <span class=m>0</span>          8d        172.16.0.156   10.0.0.3
</span></span></code></pre></td></tr></table></div></div></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5service%E6%97%A0%E6%B3%95%E8%A7%A3%E6%9E%90/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E5%85%B3%E4%BA%8E%E6%80%8E%E4%B9%88%E6%9F%A5io%E9%AB%98%E8%B4%9F%E8%BD%BD/ class=article-titles><h2 class=article-title>【问题小排查】关于怎么查IO高负载</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-09-11</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>系统如果出现 IO WAIT 高，说明 IO 设备的速度跟不上 CPU 的处理速度，CPU 需要在那里干等，
这里的等待实际也占用了 CPU 时间，导致系统负载升高，可能就会影响业务进程的处理速度，导致业务超时。</p></blockquote><h3 id=如何判断->如何判断 ？</h3><p>使用<code>top</code>命令看下当前负载：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>top - 19:42:06 up 23:59,  <span class=m>2</span> users,  load average: 34.64, 35.80, 35.76
</span></span><span class=line><span class=cl>Tasks: <span class=m>679</span> total,   <span class=m>1</span> running, <span class=m>678</span> sleeping,   <span class=m>0</span> stopped,   <span class=m>0</span> zombie
</span></span><span class=line><span class=cl>Cpu<span class=o>(</span>s<span class=o>)</span>: 15.6%us,  1.7%sy,  0.0%ni, 74.7%id,  7.9%wa,  0.0%hi,  0.1%si,  0.0%st
</span></span><span class=line><span class=cl>Mem:  32865032k total, 30989168k used,  1875864k free,   370748k buffers
</span></span><span class=line><span class=cl>Swap:  8388604k total,     5440k used,  8383164k free,  7982424k cached
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
</span></span><span class=line><span class=cl> <span class=m>9783</span> mysql     <span class=m>20</span>   <span class=m>0</span> 17.3g  16g <span class=m>8104</span> S 186.9 52.3   3752:33 mysqld
</span></span><span class=line><span class=cl> <span class=m>5700</span> nginx     <span class=m>20</span>   <span class=m>0</span> 1330m  66m <span class=m>9496</span> S  8.9  0.2   0:20.82 php-fpm
</span></span><span class=line><span class=cl> <span class=m>6424</span> nginx     <span class=m>20</span>   <span class=m>0</span> 1330m  65m <span class=m>8372</span> S  8.3  0.2   0:04.97 php-fpm
</span></span></code></pre></td></tr></table></div></div><p><code>%wa</code>(wait) 表示 IO WAIT 的 cpu 占用，默认看到的是所有核的平均值，要看每个核的<code>%wa</code>值需要按下 &ldquo;1&rdquo;:</p></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E5%85%B3%E4%BA%8E%E6%80%8E%E4%B9%88%E6%9F%A5io%E9%AB%98%E8%B4%9F%E8%BD%BD/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92crontab%E4%B8%8D%E6%89%A7%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/ class=article-titles><h2 class=article-title>【问题小排查】Linux任务计划crontab不执行的问题排查</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-08-03</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
</a>&nbsp;</li></ul><div class=article-content><p>朋友弄了一个小项目，要我帮忙做下 Linux 系统运维，上线一段时间后，发现项目偶尔会挂掉导致服务不可用。
开发朋友一时之间也没空去研究项目奔溃的根因，只好由我这个运维先写一个项目进程自拉起脚本，
通过 Linux 任务计划每分钟检查一下进程是否存在来避免项目挂了没人管的情况。</p><p>自拉起脚本很简单，随便写几行就搞定了：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span><span class=nv>processcount</span><span class=o>=</span><span class=k>$(</span>pgrep my_app<span class=p>|</span>wc -l<span class=k>)</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> <span class=k>$(</span><span class=nb>cd</span> <span class=k>$(</span>dirname <span class=nv>$0</span><span class=k>)</span> <span class=o>&amp;&amp;</span> <span class=nb>pwd</span><span class=k>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=o>[[</span> <span class=m>0</span> -eq <span class=nv>$processcount</span> <span class=o>]]</span>
</span></span><span class=line><span class=cl><span class=k>then</span>
</span></span><span class=line><span class=cl>        <span class=nb>echo</span> <span class=s2>&#34;[ </span><span class=k>$(</span>date<span class=k>)</span><span class=s2> ] : my_app is down, start it!&#34;</span> <span class=p>|</span> tee -ai ./checkprocess.log
</span></span><span class=line><span class=cl>        bash ./start.sh <span class=c1>#这里是项目的重启脚本</span>
</span></span><span class=line><span class=cl><span class=k>else</span>
</span></span><span class=line><span class=cl>        <span class=nb>echo</span> my_app is OK!
</span></span><span class=line><span class=cl><span class=k>fi</span>
</span></span></code></pre></td></tr></table></div></div><p>然后丢到 crontab，1 分钟执行一次：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>* * * * * bash /data/app_server/checkprocess.sh &gt;/dev/null 2&gt;<span class=p>&amp;</span><span class=m>1</span>
</span></span></code></pre></td></tr></table></div></div><p>-_-不过进程还是挂了</p></div><div class=article-readmore><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92crontab%E4%B8%8D%E6%89%A7%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/>Read more...</a></div><div class=article-floatclear></div></article></section></div><div class=site-footer><div class=copyright>© 2025 黄泽宏 | <a href=https://beian.miit.gov.cn/ target=_blank>粤ICP备2025417888号-1</a></div><ul class=site-footer-items><li class=site-footer-item-rsslink><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/index.xml type=application/rss+xml target=_blank title=RSS><i class="fa-solid fa-rss"></i></a></li><li class=site-footer-item-about><a href=/about/ title=About>About</a></li></ul><div class=powerdby>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://github.com/taikii/whiteplain>Whiteplain</a>
<script>fetch("https://ghtrk-pixel.fly.dev/goodtracker.png?from=hugo-footer-huangzehong_me&ts="+Date.now())</script></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-16F0MHER15"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-16F0MHER15",{anonymize_ip:!1})}</script></body></html>