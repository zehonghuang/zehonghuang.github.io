<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"><title>生产问题 - 维修区刷紫</title>
<meta property="og:title" content="生产问题 - 维修区刷紫"><meta name=twitter:title content="生产问题 - 维修区刷紫"><meta name=author content="金汤力"><link rel=icon type=image/x-icon href=/images/favicon.ico><meta property="og:site_name" content="维修区刷紫"><meta property="og:url" content="/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.120.2"><link href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/index.xml rel=alternate type=application/rss+xml title=维修区刷紫><link href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/index.xml rel=feed type=application/rss+xml title=维修区刷紫><script src=https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/Base64/1.3.0/base64.min.js integrity="sha512-IFxgh3q1bUsg/sL6qotMkJZTOvPyYSS6mRSSIVnJndN5j9vWcQ+oJyHkelIkRAOaKgdU1ibHJOs4HX15sPtZKw==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b5f7da576488071eb46ec9fe633fa64",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=/css/style.css media=all><link rel=stylesheet href=/css/style-dark.css media="all and (prefers-color-scheme: dark)"><link rel=stylesheet href=/css/syntax.css media=all><link rel=stylesheet href=/css/custom.css media=all><script src=/js/script.js></script><script src=/js/custom.js></script><script defer src=/fontawesome/all.min.js></script></head><body><header class=site-header><nav class=site-navi><h1 class=site-title><a href=/>维修区刷紫</a></h1><ul class=site-navi-items><li class=site-navi-item-archives><a href=/archives/ title=所有文章>所有文章</a></li><li class=site-navi-item-categories><a href=/categories/ title=类别>类别</a></li><li class=site-navi-item-about><a href=/about/ title=关于我>关于我</a></li></ul></nav></header><hr class=site-header-bottom><div class=main role=main><section class="list term-list"><article class=article><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98k8s%E9%80%80%E5%87%BA%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E9%97%AE%E9%A2%98/ class=article-titles><h2 class=article-title>【生产问题】K8s退出信号处理和僵尸进程问题</h2></a><ul class=article-meta><li class=article-meta-date><time>2023-01-23</time></li><li class=article-meta-categories><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/><i class="fa-solid fa-folder"></i>
生产问题
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>接上一篇容器多进程的内容延伸到僵尸进程，也是一个真实的生产问题</p><blockquote><ol><li>公司有大量的Python + Selenium爬虫服务，据开发所说一个服务有很多个并行任务</li><li>一天早上告警类似<code>Resource temporarily unavailable</code>的错误，对于这类问题其实只需根据<code>ulimit -a</code>查看各项资源即可</li><li>因为确实部分资源使用率指标，所以只能在宿主机查看缺失的资源利用情况，如果只关心进程数直接<code>ps -aux | wc -l</code></li><li>僵尸进程对于多进程服务来说是常有的事，但需要通过一些自动化手段帮助k8s清理宿主机僵尸进程</li></ol></blockquote></blockquote><h2 id=一什么是僵尸进程>一、什么是僵尸进程</h2><p>通常来说就是，在 Unix-like 操作系统中已经完成执行（终止）但仍然保留在系统进程表中的进程记录。
这种状态的进程实际上已经停止运行，不占用除进程表外的任何资源，比如CPU和内存，
但它仍然保留了一个PID和终止状态信息，等待父进程通过调用<code>wait()</code>或<code>waitpid()</code>函数来进行回收。</p><h3 id=1-生命周期>1. 生命周期</h3><ul><li><p>子进程执行完毕后，会发送一个<code>SIGCHLD</code>信号给父进程，并变为僵尸状态。</p></li><li><p>父进程通过<code>wait()</code>或<code>waitpid()</code>读取子进程的终止状态，此时操作系统会清理僵尸进程的记录，释放其PID供其他进程使用。</p></li></ul></div><div class=article-readmore><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98k8s%E9%80%80%E5%87%BA%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E9%97%AE%E9%A2%98/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%9C%A8%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%BF%90%E8%A1%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%9C%8D%E5%8A%A1oomkilled%E6%9C%AA%E8%83%BD%E8%A2%ABk8s%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB%E7%9A%84%E7%BB%93%E5%B1%80%E6%96%B9%E6%A1%88/ class=article-titles><h2 class=article-title>【生产问题】在容器中运行多进程服务OOMKilled未能被K8s检测识别的解决方案</h2></a><ul class=article-meta><li class=article-meta-date><time>2022-11-23</time></li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/><i class="fa-solid fa-folder"></i>
生产问题
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/ai%E8%AE%AD%E7%BB%83/><i class="fa-solid fa-folder"></i>
AI训练
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>这是两个月前公司的图片AI训练模型集群出现的一个生产问题，是这样的：</p><p>well-known, Python项目因为GIL普遍使用多进程代替多线程，使得container中存在1号进程之外的其他进程。</p><blockquote><ol><li>算法组的同学曾在群里反馈模型服务并没有问题，但多次跑出来的数据有缺失</li><li>开始运维方任务是算法代码问题，并没有在意，但随手发现相关的Pod内存曲线有断崖下降并且没有再回升</li><li>直觉告诉内部有进程挂了，在算法同学允许下重跑了一边服务，ps aux命令观察了一下果然若干小时候被强退，预计OOMKilled了</li><li>但主要问题是，监控系统并没有抓取到这一事件，无法发出OOMKilled告警</li></ol></blockquote></blockquote><h2 id=一container以及pod的状态>一、container以及Pod的状态</h2><h3 id=1-container的异常指标>1. container的异常指标</h3><p>总所周知，这个异常指标可以用过kube-state-metrics获得</p><pre tabindex=0><code>kube_pod_container_status_terminated_reason{ container=&#34;nginx&#34;,  namespace=&#34;default&#34;, node=&#34;xxxx&#34;, pod=&#34;nginx-dep-123&#34;, reason=&#34;OOMKilled&#34;, service=&#34;kube-state-metrics&#34;}
</code></pre><p>解读一下：意思是pod nginx-dep-123中的某个容器 nginx 的状态是terminated，并且它进入terminated状态的reason原因是因为OOMKilled</p><blockquote><p>值得注意的是，kubectl get展示的status即可能是容器也可能是pod的状态。</p><p>具体可以参考这两个官方文档<a href=https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#container-states>容器状态</a>和<a href=https://kubernetes.io/zh-cn/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase>Pod阶段</a></p></blockquote><p>容器状态只有三种：</p><ul><li>Waiting（等待）处于Waiting状态的容器仍在运行它完成启动所需要的操作：例如从某个容器镜像仓库拉取容器镜像，或者向容器应用Secret数据等等</li><li>Running（运行中） 状态表明容器正在执行状态并且没有问题发生</li><li>Terminated（已终止） 处于 Terminated 状态的容器已经开始执行并且或者正常结束或者因为某些原因失败。</li></ul><p><code>kubectl get</code>打印的源码可以在kubernetes\pkg\printers\internalversion\printers.go这里看<code>printPod()</code>方法</p><h3 id=2-containerd如何获取容器状态的>2. containerd如何获取容器状态的</h3><p>我们都知道的Pod状态均来自于CRI，kubelet的pleg会通过cri接口获取containerd的状态信息，pleg是个大坑回头有精力可以讲。</p><p>可以直接定位到pod.Status.Reason获取的位置<code>kubernetes\pkg\kubelet\pleg\generic.go</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>g</span> <span class=o>*</span><span class=nx>GenericPLEG</span><span class=p>)</span> <span class=nf>updateCache</span><span class=p>(</span><span class=nx>ctx</span> <span class=nx>context</span><span class=p>.</span><span class=nx>Context</span><span class=p>,</span> <span class=nx>pod</span> <span class=o>*</span><span class=nx>kubecontainer</span><span class=p>.</span><span class=nx>Pod</span><span class=p>,</span> <span class=nx>pid</span> <span class=nx>types</span><span class=p>.</span><span class=nx>UID</span><span class=p>)</span> <span class=p>(</span><span class=kt>error</span><span class=p>,</span> <span class=kt>bool</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=nx>pod</span> <span class=o>==</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nx>klog</span><span class=p>.</span><span class=nf>V</span><span class=p>(</span><span class=mi>4</span><span class=p>).</span><span class=nf>InfoS</span><span class=p>(</span><span class=s>&#34;PLEG: Delete status for pod&#34;</span><span class=p>,</span> <span class=s>&#34;podUID&#34;</span><span class=p>,</span> <span class=nb>string</span><span class=p>(</span><span class=nx>pid</span><span class=p>))</span>
</span></span><span class=line><span class=cl>		<span class=nx>g</span><span class=p>.</span><span class=nx>cache</span><span class=p>.</span><span class=nf>Delete</span><span class=p>(</span><span class=nx>pid</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=k>return</span> <span class=kc>nil</span><span class=p>,</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nx>g</span><span class=p>.</span><span class=nx>podCacheMutex</span><span class=p>.</span><span class=nf>Lock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=k>defer</span> <span class=nx>g</span><span class=p>.</span><span class=nx>podCacheMutex</span><span class=p>.</span><span class=nf>Unlock</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=nx>timestamp</span> <span class=o>:=</span> <span class=nx>g</span><span class=p>.</span><span class=nx>clock</span><span class=p>.</span><span class=nf>Now</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=c1>// 这里是pleg的非常重的逻辑就不展开了
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// 1. 用m.runtimeService.PodSandboxStatus获取sandbox的网络容器状态
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// 2. 再通过m.getPodContainerStatuses(uid, name, namespace)获取业务容器状态
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>//    a. 这里回去调用对应的CRI GRPC接口，即(r *remoteRuntimeService) ContainerStatus(containerID string)
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=c1>// 3. 最后拼装为&amp;kubecontainer.PodStatus
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>status</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>g</span><span class=p>.</span><span class=nx>runtime</span><span class=p>.</span><span class=nf>GetPodStatus</span><span class=p>(</span><span class=nx>ctx</span><span class=p>,</span> <span class=nx>pod</span><span class=p>.</span><span class=nx>ID</span><span class=p>,</span> <span class=nx>pod</span><span class=p>.</span><span class=nx>Name</span><span class=p>,</span> <span class=nx>pod</span><span class=p>.</span><span class=nx>Namespace</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=nx>status</span><span class=p>.</span><span class=nx>IPs</span> <span class=p>=</span> <span class=nx>g</span><span class=p>.</span><span class=nf>getPodIPs</span><span class=p>(</span><span class=nx>pid</span><span class=p>,</span> <span class=nx>status</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=c1>// ...
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=nx>err</span><span class=p>,</span> <span class=nx>g</span><span class=p>.</span><span class=nx>cache</span><span class=p>.</span><span class=nf>Set</span><span class=p>(</span><span class=nx>pod</span><span class=p>.</span><span class=nx>ID</span><span class=p>,</span> <span class=nx>status</span><span class=p>,</span> <span class=nx>err</span><span class=p>,</span> <span class=nx>timestamp</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div><div class=article-readmore><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%9C%A8%E5%AE%B9%E5%99%A8%E4%B8%AD%E8%BF%90%E8%A1%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%9C%8D%E5%8A%A1oomkilled%E6%9C%AA%E8%83%BD%E8%A2%ABk8s%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB%E7%9A%84%E7%BB%93%E5%B1%80%E6%96%B9%E6%A1%88/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E5%B0%86%E4%BC%A0%E7%BB%9F%E8%BF%90%E7%BB%B4%E7%8E%AF%E5%A2%83%E6%9C%8D%E5%8A%A1%E4%BC%98%E9%9B%85%E5%9C%B0%E8%BF%81%E7%A7%BB%E8%87%B3kubernetes%E9%9B%86%E7%BE%A4%E4%BB%8E%E8%80%8C%E5%AE%9E%E7%8E%B0%E5%85%A8%E9%87%8F%E5%AE%B9%E5%99%A8%E5%8C%96/ class=article-titles><h2 class=article-title>【生产问题】如何将传统运维环境服务优雅地迁移至Kubernetes集群从而实现全量容器化</h2></a><ul class=article-meta><li class=article-meta-date><time>2024-09-11</time></li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/><i class="fa-solid fa-folder"></i>
生产问题
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>最近尝试着面试几家公司，偶尔会被问到传统环境如何向Kubernetes迁移的方案。</p><p>坦白说，其实这方面并不缺简单可行性高的方案，我就以屈臣氏中国的迁移方案为例，给访问本博客的同行借鉴一下。</p></blockquote><h2 id=环境的迁移迁移的是什么>环境的迁移，迁移的是什么？</h2><p><strong>毋庸置疑，只要外网请求全量并正常地访问Kubernetes环境，我们就可以认为实现了容器化。</strong></p><blockquote><p>流量导入可能还不够，有的公司可能想实现全面云原生，持久层也想迁移进来，涉及到数据库如何尽最大可能无缝迁移。</p></blockquote><h3 id=流量迁移>流量迁移</h3><p>我这里直接按照阿里云传统的ECS环境迁移到自建K8s环境为例</p></div><div class=article-readmore><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%A6%82%E4%BD%95%E5%B0%86%E4%BC%A0%E7%BB%9F%E8%BF%90%E7%BB%B4%E7%8E%AF%E5%A2%83%E6%9C%8D%E5%8A%A1%E4%BC%98%E9%9B%85%E5%9C%B0%E8%BF%81%E7%A7%BB%E8%87%B3kubernetes%E9%9B%86%E7%BE%A4%E4%BB%8E%E8%80%8C%E5%AE%9E%E7%8E%B0%E5%85%A8%E9%87%8F%E5%AE%B9%E5%99%A8%E5%8C%96/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E6%97%B6%E9%9A%94%E5%A4%A7%E5%8D%8A%E5%B9%B4%E5%88%86%E4%BA%AB%E4%B8%80%E6%AC%A1nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82/ class=article-titles><h2 class=article-title>【生产问题】时隔大半年，分享一次Nginx反向代理的需求</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-11-13</time></li><li class=article-meta-categories><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/nginx/><i class="fa-solid fa-folder"></i>
Nginx
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/><i class="fa-solid fa-folder"></i>
生产问题
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>博客前面分享了一篇<a href=https://huangzehong.me/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%88%86%E4%BA%AB%E4%B8%80%E6%AC%A1nginx%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82/>《分享一个 Nginx 正向代理的另类应用案例》</a>，时隔不久，身为救火队员、万金油的博主又再一次接到了一个奇葩需求：</p></blockquote><blockquote><p>场景和上次有些类似，也是部门引进的第三方应用，部署在各个网络区域，从 OA 办公区域无法直接访问。目前，运营人员都需要登陆 Windows 跳板机，才能打开这些应用的 WEB 控制台。既不方便，而且还有一定 Windows 服务器的维护工作量，于是找到我们团队，希望通过运维手段来解决。</p></blockquote><p>拿到这个需求后，我先问了下各个应用的基本情况，得知每个应用的框架基本是一样的，都是通过 IP+端口直接访问，页面 path 也基本一样，没有唯一性。然后拿到了一个应用 WEB 控制台地址看了下，发现 html 引用的地址都是相对路径。</p><p>乍一想，这用 Nginx 代理不好弄吧？页面 path 一样，没法根据 location 来反代到不同的后端，只能通过不同 Nginx 端口来区分，那就太麻烦了！每次他们新上一个应用，我们就得多加一个新端口来映射，这种的尾大不掉、绵绵不绝事情坚决不干，Say pass。</p><p>再一想，我就想到了上次那个正向代理另类应用方案，感觉可以拿过来改改做动态代理。原理也简单：先和用户约定一个访问形式，比如:</p><blockquote><p>Nginx 代理地址为 myproxy.oa.com，需要代理到 IP 为 192.168.2.100:8080 的控制器，用户需要访问 <a href=http://myproxy.oa.com/192.168.2.100:8080/path>http://myproxy.oa.com/192.168.2.100:8080/path</a>。</p></blockquote></div><div class=article-readmore><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E6%97%B6%E9%9A%94%E5%A4%A7%E5%8D%8A%E5%B9%B4%E5%88%86%E4%BA%AB%E4%B8%80%E6%AC%A1nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82/>Read more...</a></div><div class=article-floatclear></div></article><article class=article><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%88%86%E4%BA%AB%E4%B8%80%E6%AC%A1nginx%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82/ class=article-titles><h2 class=article-title>【生产问题】分享一次Nginx正向代理的需求</h2></a><ul class=article-meta><li class=article-meta-date><time>2020-04-17</time></li><li class=article-meta-categories><a href=/categories/linux/><i class="fa-solid fa-folder"></i>
Linux
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/nginx/><i class="fa-solid fa-folder"></i>
Nginx
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/><i class="fa-solid fa-folder"></i>
生产问题
</a>&nbsp;</li></ul><div class=article-content><blockquote><p>最近接到了一个需求：通过 Nginx 代理把现网一个自研代理程序给替换掉，感觉有点意思，也有所收益，简单分享下。</p></blockquote><h3 id=需求背景>需求背景</h3><p>部门的生产环境异常复杂，有部分第三方引入的系统位于特殊网络隔离区域，请求这些系统需要通过 2 层网络代理，如图所示：</p><p><img src=/images/12.png alt=12></p><p>中心源系统请求目标系统 API 的形式各异，我简单收集了下，至少有如下 3 种：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>curl --digest -u admin:xxxxxx <span class=s1>&#39;http://10.xxx.xxx.xxx:8080/foo/boo?Id=123456789&amp;vId=1234&#39;</span> 
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>curl -d <span class=s1>&#39;{&#34;eventId&#34;: 20171116, &#34;timestamp&#34;: 123456, &#34;caller&#34;: &#34;XXP&#34;, &#34;version&#34;: &#34;1.0&#34;, &#34;interface&#34;: {&#34;interfaceName&#34;: &#34;XXPVC&#34;, &#34;para&#34;: {&#34;detail&#34;: {&#34;owner&#34;: &#34;xxxxxxx&#34;}}}, &#34;password&#34;: &#34;xxxxxx&#34;, &#34;callee&#34;: &#34;XXPVC&#34;}&#39;</span> http://10.x.x.x:8080/t/api
</span></span><span class=line><span class=cl> 
</span></span><span class=line><span class=cl>curl -X PUT -H <span class=s2>&#34;Content-Type: application/json&#34;</span> -d<span class=s1>&#39;{&#34;vp&#34;:{&#34;id&#34;:&#34;ab27adc8-xxx-xxxx-a732-fbde162ebdd3&#34;}}&#39;</span> <span class=s2>&#34;http://10.x.x.x/v1.0/peers/show_connectioninfos&#34;</span>
</span></span></code></pre></td></tr></table></div></div></div><div class=article-readmore><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%E5%88%86%E4%BA%AB%E4%B8%80%E6%AC%A1nginx%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E9%9C%80%E6%B1%82/>Read more...</a></div><div class=article-floatclear></div></article></section></div><div class=site-footer><div class=copyright>© 2025 黄泽宏 | <a href=https://beian.miit.gov.cn/ target=_blank>粤ICP备2025417888号-1</a></div><ul class=site-footer-items><li class=site-footer-item-rsslink><a href=/categories/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/index.xml type=application/rss+xml target=_blank title=RSS><i class="fa-solid fa-rss"></i></a></li><li class=site-footer-item-about><a href=/about/ title=About>About</a></li></ul><div class=powerdby>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://github.com/taikii/whiteplain>Whiteplain</a>
<script>fetch("https://ghtrk-pixel.fly.dev/goodtracker.png?from=hugo-footer-huangzehong_me&ts="+Date.now())</script></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-16F0MHER15"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-16F0MHER15",{anonymize_ip:!1})}</script></body></html>