<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"><title>【深度解析】详细梳理Kubernetes的网络模型，总结网络故障排查核心思路 - 维修区刷紫</title>
<meta property="og:title" content="【深度解析】详细梳理Kubernetes的网络模型，总结网络故障排查核心思路 - 维修区刷紫"><meta name=twitter:title content="【深度解析】详细梳理Kubernetes的网络模型，总结网络故障排查核心思路 - 维修区刷紫"><meta name=description content="本文旨在梳理网络模型，总结出通用并且高可行性的故障排查思路，并且能通过自动化检测减少中大规模集群的手动排查工作。


1


默认读者已熟悉四层/七层网络模型，相关概念不再赘述


一、Linux中的基础网络技术
这里只会提及相关的Linux指令，不深入技术原理，只会一笔带过，不然文章会很冗长。
1. Network namespace
我们知道两个POD的网络相互隔离，实际在操作系统中是通过命名空间实现的。
Network namespace用于支持网络协议栈的多个实例。通过对网络资源的隔离，就能在一个宿主机上虚拟出多个不同的网络环境。docker利用NS实现了不同容器的网络隔离。
Network namespace可以提供独立的路由表和iptables来设置包转发、nat以及ip包过滤等功能，提供完整且独立的协议栈。


1
2
3
4


## 创建一个新的网络命名空间
sudo ip netns add my_namespace
## 进入my_namespace的内部 shell 界面
sudo ip netns exec my_namespace bash


2. veth设备对
那如何我们如何为两个不同命名空间下的进程之间实现通信呢？
可以通过引入Veth设备对，Veth设备都是成对出现的，其中一端成为另一端的peer，在Veth设备的一端发送数据时，会将数据发送到另一端，并触发接收数据的操作。"><meta property="og:description" content="本文旨在梳理网络模型，总结出通用并且高可行性的故障排查思路，并且能通过自动化检测减少中大规模集群的手动排查工作。


1


默认读者已熟悉四层/七层网络模型，相关概念不再赘述


一、Linux中的基础网络技术
这里只会提及相关的Linux指令，不深入技术原理，只会一笔带过，不然文章会很冗长。
1. Network namespace
我们知道两个POD的网络相互隔离，实际在操作系统中是通过命名空间实现的。
Network namespace用于支持网络协议栈的多个实例。通过对网络资源的隔离，就能在一个宿主机上虚拟出多个不同的网络环境。docker利用NS实现了不同容器的网络隔离。
Network namespace可以提供独立的路由表和iptables来设置包转发、nat以及ip包过滤等功能，提供完整且独立的协议栈。


1
2
3
4


## 创建一个新的网络命名空间
sudo ip netns add my_namespace
## 进入my_namespace的内部 shell 界面
sudo ip netns exec my_namespace bash


2. veth设备对
那如何我们如何为两个不同命名空间下的进程之间实现通信呢？
可以通过引入Veth设备对，Veth设备都是成对出现的，其中一端成为另一端的peer，在Veth设备的一端发送数据时，会将数据发送到另一端，并触发接收数据的操作。"><meta name=twitter:description content="本文旨在梳理网络模型，总结出通用并且高可行性的故障排查思路，并且能通过自动化检测减少中大规模集群的手动排查工作。


1


默认读者已熟悉四层/七层网络模型，相关概念不再赘述


一、Linux中的基础网络技术
这里只会提及相关的Linux指令，不深入技术原理，只会一笔带过，不然文章会很冗长。
1. Network namespace
我们知道两个POD的网络相互隔离，实际在操作系统中是通过命名 …"><meta name=author content="金汤力"><link rel=icon type=image/x-icon href=/images/favicon.ico><meta property="og:site_name" content="维修区刷紫"><meta property="og:url" content="/kubernetes%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF/"><meta property="og:type" content="article"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.120.2"><script src=https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/Base64/1.3.0/base64.min.js integrity="sha512-IFxgh3q1bUsg/sL6qotMkJZTOvPyYSS6mRSSIVnJndN5j9vWcQ+oJyHkelIkRAOaKgdU1ibHJOs4HX15sPtZKw==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b5f7da576488071eb46ec9fe633fa64",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=/css/style.css media=all><link rel=stylesheet href=/css/style-dark.css media="all and (prefers-color-scheme: dark)"><link rel=stylesheet href=/css/syntax.css media=all><link rel=stylesheet href=/css/custom.css media=all><script src=/js/script.js></script><script src=/js/custom.js></script><script defer src=/fontawesome/all.min.js></script></head><body><header class=site-header><nav class=site-navi><h1 class=site-title><a href=/>维修区刷紫</a></h1><ul class=site-navi-items><li class=site-navi-item-archives><a href=/archives/ title=所有文章>所有文章</a></li><li class=site-navi-item-categories><a href=/categories/ title=类别>类别</a></li><li class=site-navi-item-about><a href=/about/ title=关于我>关于我</a></li></ul></nav></header><hr class=site-header-bottom><div class=main role=main><article class=article><h1 class=article-title>【深度解析】详细梳理Kubernetes的网络模型，总结网络故障排查核心思路</h1><hr class=article-title-bottom><ul class=article-meta><li class=article-meta-date><time>2022-07-03</time></li><li class=article-meta-categories><a href=/categories/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/><i class="fa-solid fa-folder"></i>
深度解析
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><aside class=toc><nav id=TableOfContents><ul><li><a href=#一linux中的基础网络技术>一、Linux中的基础网络技术</a><ul><li><a href=#1-network-namespace>1. Network namespace</a></li><li><a href=#2-veth设备对>2. veth设备对</a></li><li><a href=#3-网桥bridge>3. 网桥bridge</a></li><li><a href=#4-iptables转发功能>4. iptables转发功能</a></li><li><a href=#5-vxlanip-in-ip>5. VxLan、IP-in-IP</a></li></ul></li><li><a href=#二pod之间通信>二、POD之间通信</a><ul><li><a href=#0-同一个pod中容器间的网络环境>0. 同一个Pod中容器间的网络环境</a></li><li><a href=#1-同一个节点的pod之间>1. 同一个节点的Pod之间</a></li><li><a href=#2-跨节点的pod之间>2. 跨节点的Pod之间</a></li></ul></li><li><a href=#三域名访问负载均衡>三、域名访问、负载均衡</a><ul><li><a href=#0-clusterip和headless>0. ClusterIP和Headless</a></li><li><a href=#1-iptables如何路由clusterip>1. iptables如何路由ClusterIP</a></li><li><a href=#2-kube-proxy和coredns>2. kube-proxy和CoreDNS</a></li></ul></li><li><a href=#四常见的非硬件的网络问题>四、常见的非硬件的网络问题</a></li></ul></nav></aside><p>本文旨在梳理网络模型，总结出通用并且高可行性的故障排查思路，并且能通过自动化检测减少中大规模集群的手动排查工作。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>默认读者已熟悉四层/七层网络模型，相关概念不再赘述
</span></span></code></pre></td></tr></table></div></div><h2 id=一linux中的基础网络技术>一、Linux中的基础网络技术</h2><p>这里只会提及相关的Linux指令，不深入技术原理，只会一笔带过，不然文章会很冗长。</p><h3 id=1-network-namespace>1. Network namespace</h3><p>我们知道两个POD的网络相互隔离，实际在操作系统中是通过命名空间实现的。</p><p>Network namespace用于支持网络协议栈的多个实例。通过对网络资源的隔离，就能在一个宿主机上虚拟出多个不同的网络环境。docker利用NS实现了不同容器的网络隔离。
Network namespace可以提供独立的路由表和iptables来设置包转发、nat以及ip包过滤等功能，提供完整且独立的协议栈。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 创建一个新的网络命名空间</span>
</span></span><span class=line><span class=cl>sudo ip netns add my_namespace
</span></span><span class=line><span class=cl><span class=c1>## 进入my_namespace的内部 shell 界面</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> my_namespace bash
</span></span></code></pre></td></tr></table></div></div><h3 id=2-veth设备对>2. veth设备对</h3><p>那如何我们如何为两个不同命名空间下的进程之间实现通信呢？</p><p>可以通过引入Veth设备对，Veth设备都是成对出现的，其中一端成为另一端的peer，在Veth设备的一端发送数据时，会将数据发送到另一端，并触发接收数据的操作。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo ip netns add ns1
</span></span><span class=line><span class=cl>sudo ip netns add ns2
</span></span><span class=line><span class=cl><span class=c1>## 创建一对 veth 设备，这里我们命名为 veth0 和 veth1，注意当前设备对为创建在任何命名空间中</span>
</span></span><span class=line><span class=cl>sudo ip link add veth0 <span class=nb>type</span> veth peer name veth1
</span></span><span class=line><span class=cl><span class=c1>## 将 veth0 分配到 ns1，将 veth1 分配到 ns2，将peer转移到各自的命名空间</span>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> veth0 netns ns1
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> veth1 netns ns2
</span></span><span class=line><span class=cl><span class=c1>## 在ns1里能看到相关的设备信息</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ip link show
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=m>65536</span> qdisc noqueue state UNKNOWN mode DEFAULT group default qlen <span class=m>1000</span>
</span></span><span class=line><span class=cl>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span class=line><span class=cl>2: veth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=m>1500</span> qdisc pfifo_fast state UP mode DEFAULT group default qlen <span class=m>1000</span>
</span></span><span class=line><span class=cl>    link/ether 01:23:45:67:89:ab brd ff:ff:ff:ff:ff:ff
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 为两个 veth 设备分配 IP 地址，确保它们在同一子网中</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ip addr add 192.168.1.1/24 dev veth0
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns2 ip addr add 192.168.1.2/24 dev veth1
</span></span><span class=line><span class=cl><span class=c1>## 启动两个接口</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ip link <span class=nb>set</span> veth0 up
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns2 ip link <span class=nb>set</span> veth1 up
</span></span><span class=line><span class=cl><span class=c1>## 可以在两个命名空间之间测试连接，可以从 ns1 ping ns2</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ping 192.168.1.2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 可以通过 ethtool 工具可以在一端查看对端设接口</span>
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ethtool -S veth0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>NIC statistics:
</span></span><span class=line><span class=cl>     peer_ifindex: <span class=m>3</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=3-网桥bridge>3. 网桥bridge</h3><p>在有多个网络命名空间和多个veth设备对的情况下，即在本机有多个POD，使用网桥（bridge）可以提供更好的管理和网络连通性，它充当一个虚拟的交换机，可以将多个网络接口连接在一起，使它们在同一个网络层次中互相通信。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 创建并启动网桥</span>
</span></span><span class=line><span class=cl>sudo ip link add name br0 <span class=nb>type</span> bridge
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> br0 up
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 类似 calico 这种，放在网桥的设备名称通常是 caliXXXXXXX，而在 Pod 或者容器中的设备名称被命名为 eth0</span>
</span></span><span class=line><span class=cl>sudo ip link add veth0 <span class=nb>type</span> veth peer name br-veth0
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> br-veth0 master br0
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> br-veth0 up
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> veth0 netns ns1
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ip addr add 192.168.1.123/24 dev veth0
</span></span><span class=line><span class=cl>sudo ip netns <span class=nb>exec</span> ns1 ip link <span class=nb>set</span> veth0 up
</span></span></code></pre></td></tr></table></div></div><p>经过以上创建veth设备和网桥后，执行<code>ip route</code>可以看到以下这行记录。calico为容器创建网络环境后，也会有类似的记录。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>blackhole 192.168.1.123/26 proto bird
</span></span><span class=line><span class=cl>192.168.1.123 dev br-veth0 scope link
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 你在Kubernetes集群的节点执行同样的命令，能看到类似的记录</span>
</span></span><span class=line><span class=cl>10.244.166.168 dev calie8098ed1v42d scope link
</span></span></code></pre></td></tr></table></div></div><h3 id=4-iptables转发功能>4. iptables转发功能</h3><p>Kubernetes中通常不直接访问Pod IP，而是通过Service的ClusterIP访问，ClusterIP是一个虚拟的逻辑IP，通过iptables进行负载均衡+转发。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 开启 IP 转发功能</span>
</span></span><span class=line><span class=cl>sudo sysctl -w net.ipv4.ip_forward<span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 这里关系到为什么PodIP报文都需要发至网关，后面会说明。</span>
</span></span><span class=line><span class=cl><span class=c1>## 开启iptables支持对brigde的转发 </span>
</span></span><span class=line><span class=cl>sudo sysctl net.bridge.bridge-nf-call-iptables<span class=o>=</span><span class=m>1</span>
</span></span><span class=line><span class=cl>sudo sysctl net.bridge.bridge-nf-call-ip6tables<span class=o>=</span><span class=m>1</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=5-vxlanip-in-ip>5. VxLan、IP-in-IP</h3><ul><li>VxLan</li></ul><p>目前主流CNI中，Flannel支持该模式</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo modprobe vxlan
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 对点对可以用以下方式，比如仅有两个host分别是192.168.1.1和192.168.1.2</span>
</span></span><span class=line><span class=cl><span class=c1>## sudo ip link add vxlan0 type vxlan id 42 dev eth0 remote 192.168.1.2 dstport 4789</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 如果有多台机器，可以基于交换机自持的多播组，这里指定多播组239.1.1.1</span>
</span></span><span class=line><span class=cl><span class=c1>## 在每台机器执行该指令</span>
</span></span><span class=line><span class=cl><span class=c1>## 需要注意一点，Flannel是通过监听etcd的Node资源变化来在本机添加的，并不是通用交换机的多播组，这是为了兼顾更多的集群网络场景</span>
</span></span><span class=line><span class=cl>sudo ip link add vxlan0 <span class=nb>type</span> vxlan id <span class=m>42</span> group 239.1.1.1 dev eth0 dstport <span class=m>4789</span>
</span></span><span class=line><span class=cl><span class=c1>## 启动</span>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> vxlan0 up
</span></span><span class=line><span class=cl><span class=c1>## 在每台host添加属于自己的虚拟IP范围</span>
</span></span><span class=line><span class=cl>sudo ip addr add 10.0.0.1/24 dev vxlan0
</span></span></code></pre></td></tr></table></div></div><ul><li>IP-in-IP</li></ul><p>Kubernetes的默认CNI calico的默认模式，另外一种叫BGP</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo modprobe ipip
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 为每台机器创建有个ipip隧道，并且启动</span>
</span></span><span class=line><span class=cl>sudo ip tunnel add tunl0 mode ipip <span class=nb>local</span> 192.168.1.1 ttl <span class=m>255</span>
</span></span><span class=line><span class=cl>sudo ip link <span class=nb>set</span> tunl0 up
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 为每段子网以及对应的宿主机添加记录</span>
</span></span><span class=line><span class=cl>sudo ip route add 10.0.0.2/24 via 192.168.1.2 dev tunl0 proto bird
</span></span><span class=line><span class=cl>sudo ip route add 10.0.0.3/24 via 192.168.1.3 dev tunl0 proto bird
</span></span></code></pre></td></tr></table></div></div><ul><li>两种的区别</li></ul><p>就我个人所遇到的使用场景来说，我会觉得VxLan更适合大规模集群，因为本身支持多层的网络拓扑（IP-in-IP不支持），但是不断的解析报头封装报头也带来了额外网络开销，会带来不必要的延迟。</p><h2 id=二pod之间通信>二、POD之间通信</h2><p>下图基本上展示了 Kubernetes 的容器基础网络模型，下图中的所有接口设备容器的eth0、网桥的calixxxx、宿主机eth0等都可以被tcpdump监听，我们可以通过它探索整个通讯流程。</p><p><img src=/images/%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.png alt=基础网络模型></p><h3 id=0-同一个pod中容器间的网络环境>0. 同一个Pod中容器间的网络环境</h3><p>很多文章都讲过 Kubernetes 都会为每个 Pod 创建一个sanxbox或者叫pause的基础容器，Pod 中的其他 container 加入 cri/cni 为该基础容器所创建的网络命名空间，达到同一个 Pod 中容器间共享网络环境的效果。</p><p>事实上 Docker 有container网络模式，该模式允许一个容器共享另一个容器的网络命名空间</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 我们可以通过Docker命令手动创建一个基于pause基础容器实现多容器共享某个网络命名空间 </span>
</span></span><span class=line><span class=cl>docker run -d --name nginx -v <span class=sb>`</span><span class=nb>pwd</span><span class=sb>`</span>/nginx.conf:/etc/nginx/nginx.conf --net<span class=o>=</span>container:pause --ipc<span class=o>=</span>container:pause --pid<span class=o>=</span>container:pause --ipc<span class=o>=</span>shareable nginx
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>##  --net=container:pause 让nginx与pause共享命名空间</span>
</span></span><span class=line><span class=cl><span class=c1>##  --ipc=container:pause 允许在两个容器之间进行进程间通信</span>
</span></span><span class=line><span class=cl><span class=c1>##  --pid=container:pause 多个容器可以看到彼此的进程，并可以互相影响进程</span>
</span></span><span class=line><span class=cl><span class=c1>##  --ipc=shareable       设置 IPC 命名空间为可共享的</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=1-同一个节点的pod之间>1. 同一个节点的Pod之间</h3><p>我们需要确认一点就是 calico 为例，默认在同一个节点 Pod 都在同一个网段，通过<code>ip route show</code>可以看出来。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@k8s-master01 ~<span class=o>]</span><span class=c1># ip route show</span>
</span></span><span class=line><span class=cl>default via 10.0.17.1 dev ens160 proto dhcp metric <span class=m>100</span> 
</span></span><span class=line><span class=cl>10.0.17.0/24 dev ens160 proto kernel scope link src 10.0.17.5 metric <span class=m>100</span> 
</span></span><span class=line><span class=cl>blackhole 10.100.32.128/26 proto bird 
</span></span><span class=line><span class=cl>10.100.32.129 dev calib8398c29e44 scope link 
</span></span><span class=line><span class=cl>10.100.32.130 dev cali8f0eab1f8f3 scope link 
</span></span><span class=line><span class=cl>10.100.32.131 dev cali264ca4ab91d scope link 
</span></span><span class=line><span class=cl>10.100.32.132 dev calie82e19a348e scope link 
</span></span><span class=line><span class=cl>10.100.32.133 dev califd92bc1f55b scope link 
</span></span><span class=line><span class=cl>10.100.32.134 dev calibf639a2fbff scope link 
</span></span><span class=line><span class=cl>10.100.58.192/26 via 10.0.17.7 dev tunl0 proto bird onlink 
</span></span><span class=line><span class=cl>10.100.85.192/26 via 10.0.17.6 dev tunl0 proto bird onlink 
</span></span></code></pre></td></tr></table></div></div><p>同一个网段的设备可以通过网关ARP获取到目标MAC地址，原设备不在需要网关而是直接通过链路层从端口将报文发送至目标设备。</p><p>但对于 Kubernetes 来说，当CNI，尤其是calico这种基于 iptables/route 实现了策略规则功能，并不希望任何PodIP走链路层而绕过iptables等路由规则，都属于网络层，需要让报文至少经过一次IP层，才能使策略生效。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 在每个容器中执行该命令，都能看到以下输出</span>
</span></span><span class=line><span class=cl>sudo route -n
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Destination     Gateway         Genmask         Flags   Metric  Ref  Use  Iface 
</span></span><span class=line><span class=cl>0.0.0.0         169.254.1.1     0.0.0.0         UG      <span class=m>0</span>       <span class=m>0</span>    <span class=m>0</span>    eth0 
</span></span><span class=line><span class=cl>169.254.1.1     0.0.0.0         255.255.255.255 UH      <span class=m>0</span>       <span class=m>0</span>    <span class=m>0</span>    eth0
</span></span></code></pre></td></tr></table></div></div><p>calico会将 brigde 的 ip 和 mac 分别设置为<code>169.254.1.1</code>和<code>ee:ee:ee:ee:ee:ee</code>，并且通过以上配置，强制所有 IP 都需要经过作为网关的网桥。
网桥作为网关转发给其他设备接口，也就需要配置<code>net.bridge.bridge-nf-call-iptables=1</code>。下面是某个 http 请求的抓包数据</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Ethernet II, Src: 72:13:7d:48:a5:d6 <span class=o>(</span>72:13:7d:48:a5:d6<span class=o>)</span>, Dst: ee:ee:ee:ee:ee:ee <span class=o>(</span>ee:ee:ee:ee:ee:ee<span class=o>)</span>
</span></span><span class=line><span class=cl>    Destination: ee:ee:ee:ee:ee:ee <span class=o>(</span>ee:ee:ee:ee:ee:ee<span class=o>)</span>
</span></span><span class=line><span class=cl>        Address: ee:ee:ee:ee:ee:ee <span class=o>(</span>ee:ee:ee:ee:ee:ee<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ..1. .... .... .... .... <span class=o>=</span> LG bit: Locally administered address <span class=o>(</span>this is NOT the factory default<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ...0 .... .... .... .... <span class=o>=</span> IG bit: Individual address <span class=o>(</span>unicast<span class=o>)</span>
</span></span><span class=line><span class=cl>    Source: 72:13:7d:48:a5:d6 <span class=o>(</span>72:13:7d:48:a5:d6<span class=o>)</span>
</span></span><span class=line><span class=cl>        Address: 72:13:7d:48:a5:d6 <span class=o>(</span>72:13:7d:48:a5:d6<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ..1. .... .... .... .... <span class=o>=</span> LG bit: Locally administered address <span class=o>(</span>this is NOT the factory default<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ...0 .... .... .... .... <span class=o>=</span> IG bit: Individual address <span class=o>(</span>unicast<span class=o>)</span>
</span></span><span class=line><span class=cl>    Type: IPv4 <span class=o>(</span>0x0800<span class=o>)</span>
</span></span></code></pre></td></tr></table></div></div><p>如何抓 container 的请求报文，具体命令如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>kubectl get pod &lt;pod-name&gt; -n &lt;namespace&gt; -o <span class=nv>jsonpath</span><span class=o>=</span><span class=s1>&#39;{.status.containerStatuses[0].containerID}&#39;</span>
</span></span><span class=line><span class=cl><span class=c1>## containerd://722bc322872c8830b30839dbac81bb8e0300724896945edeea29118f9a01b8de</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>crictl inspect --output go-template --template <span class=s1>&#39;{{.info.pid}}&#39;</span> 722bc322872c8830b30839dbac81bb8e0300724896945edeea29118f9a01b8de
</span></span><span class=line><span class=cl><span class=c1>## 28983</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sudo nsenter -t <span class=m>28983</span> -n
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>[</span>root@k8s-node01 ~<span class=o>]</span><span class=c1># ip link show</span>
</span></span><span class=line><span class=cl>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=m>65536</span> qdisc noqueue state UNKNOWN mode DEFAULT group default qlen <span class=m>1000</span>
</span></span><span class=line><span class=cl>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span class=line><span class=cl>2: tunl0@NONE: &lt;NOARP&gt; mtu <span class=m>1480</span> qdisc noop state DOWN mode DEFAULT group default qlen <span class=m>1000</span>
</span></span><span class=line><span class=cl>    link/ipip 0.0.0.0 brd 0.0.0.0
</span></span><span class=line><span class=cl>4: eth0@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=m>1480</span> qdisc noqueue state UP mode DEFAULT group default qlen <span class=m>1000</span>
</span></span><span class=line><span class=cl>    link/ether 72:13:7d:48:a5:d6 brd ff:ff:ff:ff:ff:ff link-netnsid <span class=m>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>tcpdump -i eth0 -w /tmp/capture.pcap
</span></span></code></pre></td></tr></table></div></div><h3 id=2-跨节点的pod之间>2. 跨节点的Pod之间</h3><p>测试环境只开启了 IPIP 模式，所以这里暂时讨论这一种模式。</p><p>通过抓取宿主机网卡的报文，可以看到有两层 IPV4 的报头，其中一个为<code>Protocol: IPIP (4)</code>，目标主机接到报文后，会先进入IPIP隧道解包再进入iptables。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>Internet Protocol Version 4, Src: 10.0.17.6, Dst: 10.0.17.7
</span></span><span class=line><span class=cl>    <span class=m>0100</span> .... <span class=o>=</span> Version: <span class=m>4</span>
</span></span><span class=line><span class=cl>    .... <span class=nv>0101</span> <span class=o>=</span> Header Length: <span class=m>20</span> bytes <span class=o>(</span>5<span class=o>)</span>
</span></span><span class=line><span class=cl>    Differentiated Services Field: 0x00 <span class=o>(</span>DSCP: CS0, ECN: Not-ECT<span class=o>)</span>
</span></span><span class=line><span class=cl>        <span class=m>0000</span> 00.. <span class=o>=</span> Differentiated Services Codepoint: Default <span class=o>(</span>0<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ..00 <span class=o>=</span> Explicit Congestion Notification: Not ECN-Capable Transport <span class=o>(</span>0<span class=o>)</span>
</span></span><span class=line><span class=cl>    Total Length: <span class=m>221</span>
</span></span><span class=line><span class=cl>    Identification: 0xf398 <span class=o>(</span>62360<span class=o>)</span>
</span></span><span class=line><span class=cl>    010. .... <span class=o>=</span> Flags: 0x2, Don<span class=s1>&#39;t fragment
</span></span></span><span class=line><span class=cl><span class=s1>        0... .... = Reserved bit: Not set
</span></span></span><span class=line><span class=cl><span class=s1>        .1.. .... = Don&#39;</span>t fragment: Set
</span></span><span class=line><span class=cl>        ..0. .... <span class=o>=</span> More fragments: Not <span class=nb>set</span>
</span></span><span class=line><span class=cl>    ...0 <span class=m>0000</span> <span class=m>0000</span> <span class=nv>0000</span> <span class=o>=</span> Fragment Offset: <span class=m>0</span>
</span></span><span class=line><span class=cl>    Time to Live: <span class=m>63</span>
</span></span><span class=line><span class=cl>    Protocol: IPIP <span class=o>(</span>4<span class=o>)</span>
</span></span><span class=line><span class=cl>    Header Checksum: 0x1178 <span class=o>[</span>validation disabled<span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=o>[</span>Header checksum status: Unverified<span class=o>]</span>
</span></span><span class=line><span class=cl>    Source Address: 10.0.17.6
</span></span><span class=line><span class=cl>    Destination Address: 10.0.17.7
</span></span><span class=line><span class=cl>Internet Protocol Version 4, Src: 10.100.85.207, Dst: 10.100.58.221
</span></span><span class=line><span class=cl>    <span class=m>0100</span> .... <span class=o>=</span> Version: <span class=m>4</span>
</span></span><span class=line><span class=cl>    .... <span class=nv>0101</span> <span class=o>=</span> Header Length: <span class=m>20</span> bytes <span class=o>(</span>5<span class=o>)</span>
</span></span><span class=line><span class=cl>    Differentiated Services Field: 0x00 <span class=o>(</span>DSCP: CS0, ECN: Not-ECT<span class=o>)</span>
</span></span><span class=line><span class=cl>        <span class=m>0000</span> 00.. <span class=o>=</span> Differentiated Services Codepoint: Default <span class=o>(</span>0<span class=o>)</span>
</span></span><span class=line><span class=cl>        .... ..00 <span class=o>=</span> Explicit Congestion Notification: Not ECN-Capable Transport <span class=o>(</span>0<span class=o>)</span>
</span></span><span class=line><span class=cl>    Total Length: <span class=m>201</span>
</span></span><span class=line><span class=cl>    Identification: 0x2d0d <span class=o>(</span>11533<span class=o>)</span>
</span></span><span class=line><span class=cl>    010. .... <span class=o>=</span> Flags: 0x2, Don<span class=s1>&#39;t fragment
</span></span></span><span class=line><span class=cl><span class=s1>        0... .... = Reserved bit: Not set
</span></span></span><span class=line><span class=cl><span class=s1>        .1.. .... = Don&#39;</span>t fragment: Set
</span></span><span class=line><span class=cl>        ..0. .... <span class=o>=</span> More fragments: Not <span class=nb>set</span>
</span></span><span class=line><span class=cl>    ...0 <span class=m>0000</span> <span class=m>0000</span> <span class=nv>0000</span> <span class=o>=</span> Fragment Offset: <span class=m>0</span>
</span></span><span class=line><span class=cl>    Time to Live: <span class=m>63</span>
</span></span><span class=line><span class=cl>    Protocol: TCP <span class=o>(</span>6<span class=o>)</span>
</span></span><span class=line><span class=cl>    Header Checksum: 0x68ae <span class=o>[</span>validation disabled<span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=o>[</span>Header checksum status: Unverified<span class=o>]</span>
</span></span><span class=line><span class=cl>    Source Address: 10.100.85.207
</span></span><span class=line><span class=cl>    Destination Address: 10.100.58.221
</span></span></code></pre></td></tr></table></div></div><p>可以通用下面命令查看宿主机有多少 IPIP 规则。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sudo ip tunnel show <span class=p>|</span> grep ipip
</span></span><span class=line><span class=cl><span class=c1>## 一般来说，calico的IPIP模式下都会得到下面的输出，不限制tunl0两端的IP，任意IP都走IPIP隧道</span>
</span></span><span class=line><span class=cl>tunl0: ip/ip remote any <span class=nb>local</span> any ttl inherit nopmtudisc
</span></span></code></pre></td></tr></table></div></div><h2 id=三域名访问负载均衡>三、域名访问、负载均衡</h2><p>一般情况下，我们不会直接获取PodIP进行网络通信，因为PodIP一样不被持久化，restart Pod后会重新分配。
我们需要通过Service进行访问，可以请求Service提供的Cluster，也能通过它的域名。</p><h3 id=0-clusterip和headless>0. ClusterIP和Headless</h3><p>ClusterIP就是vip，Headless没有负载均衡和vip，而是直接返回PodIP列表。对于开发来说，客户端负载均衡更多使用后者，下图是一个headless Service。
就不需要多说了，相当于直接访问POD。</p><p>可以抓取容器中 eth0 网卡看到 dns 请求报文</p><p><img src=/images/dump_dns.png alt="alt text"></p><h3 id=1-iptables如何路由clusterip>1. iptables如何路由ClusterIP</h3><p>这里就直接用CoreDNS的Service来举例了</p><p><img src=/images/dns-service.png alt=img.png></p><p>下面是一个Service所生成的iptables完整链路，ClusterIP只是一个逻辑目标IP，在Pod对ClusterIP进行请求是，
brigde会将报文转发至iptables并进行过滤和NAT，最后回到Pod之间的网络通信。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1>## 这是NAT OUTPUT链的一部分</span>
</span></span><span class=line><span class=cl>*nat
</span></span><span class=line><span class=cl><span class=c1>## 因为是请求ClusterIP，所以从OUTPUT链为开始</span>
</span></span><span class=line><span class=cl>-A OUTPUT -m comment --comment <span class=s2>&#34;kubernetes service portals&#34;</span> -j KUBE-SERVICES
</span></span><span class=line><span class=cl><span class=c1>## 对CoreDNS的是两个端口两种协议做规则匹配</span>
</span></span><span class=line><span class=cl>-A KUBE-SERVICES -d 10.96.0.10/32 -p tcp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp cluster IP&#34;</span> -m tcp --dport <span class=m>53</span> -j KUBE-SVC-ERIFXISQEP7F7OF4
</span></span><span class=line><span class=cl>-A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns cluster IP&#34;</span> -m udp --dport <span class=m>53</span> -j KUBE-SVC-TCOU7JCQXEZGVUNU
</span></span><span class=line><span class=cl><span class=c1>## 源IP非CIDR池里的IP，跳转至KUBE-MARK-MASQ</span>
</span></span><span class=line><span class=cl>-A KUBE-SVC-ERIFXISQEP7F7OF4 ! -s 10.100.0.0/16 -d 10.96.0.10/32 -p tcp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp cluster IP&#34;</span> -m tcp --dport <span class=m>53</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl><span class=c1>## 5050随机负载均衡</span>
</span></span><span class=line><span class=cl>-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp -&gt; 10.100.32.131:53&#34;</span> -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-APPOXWYHNPQM3A5Z
</span></span><span class=line><span class=cl>-A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp -&gt; 10.100.32.134:53&#34;</span> -j KUBE-SEP-S5GWZTRHIEZICHHY
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>-A KUBE-SVC-TCOU7JCQXEZGVUNU ! -s 10.100.0.0/16 -d 10.96.0.10/32 -p udp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns cluster IP&#34;</span> -m udp --dport <span class=m>53</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl>-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns -&gt; 10.100.32.131:53&#34;</span> -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-7J3PXXC746AAT6A4
</span></span><span class=line><span class=cl>-A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns -&gt; 10.100.32.134:53&#34;</span> -j KUBE-SEP-WSVKKSCEUEP4LICT
</span></span><span class=line><span class=cl><span class=c1>## 先排除掉源IP为自己的请求，跳转至KUBE-MARK-MASQ</span>
</span></span><span class=line><span class=cl>-A KUBE-SEP-7J3PXXC746AAT6A4 -s 10.100.32.131/32 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns&#34;</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl><span class=c1>## 最后匹配成功，进行NAT跳转至真实的PodIP，完成请求</span>
</span></span><span class=line><span class=cl>-A KUBE-SEP-7J3PXXC746AAT6A4 -p udp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns&#34;</span> -m udp -j DNAT --to-destination 10.100.32.131:53
</span></span><span class=line><span class=cl>-A KUBE-SEP-APPOXWYHNPQM3A5Z -s 10.100.32.131/32 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp&#34;</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl>-A KUBE-SEP-APPOXWYHNPQM3A5Z -p tcp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp&#34;</span> -m tcp -j DNAT --to-destination 10.100.32.131:53
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>-A KUBE-SEP-WSVKKSCEUEP4LICT -s 10.100.32.134/32 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns&#34;</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl>-A KUBE-SEP-WSVKKSCEUEP4LICT -p udp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns&#34;</span> -m udp -j DNAT --to-destination 10.100.32.134:53
</span></span><span class=line><span class=cl>-A KUBE-SEP-S5GWZTRHIEZICHHY -s 10.100.32.134/32 -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp&#34;</span> -j KUBE-MARK-MASQ
</span></span><span class=line><span class=cl>-A KUBE-SEP-S5GWZTRHIEZICHHY -p tcp -m comment --comment <span class=s2>&#34;kube-system/kube-dns:dns-tcp&#34;</span> -m tcp -j DNAT --to-destination 10.100.32.134:53
</span></span><span class=line><span class=cl><span class=c1>## 所有不被匹配的源IP，都被打上标签，在POSTROUTING会直接退出Kubernetes集群的规则匹配</span>
</span></span><span class=line><span class=cl>-A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## 路由出口，结束规则匹配</span>
</span></span><span class=line><span class=cl>-A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN
</span></span></code></pre></td></tr></table></div></div><h3 id=2-kube-proxy和coredns>2. kube-proxy和CoreDNS</h3><h4 id=kube-proxy>kube-proxy</h4><p>我们知道Kube-Proxy实际上就是监听每个Service及其EndPoint列表，当出现变化的时候，都会更新至iptables/ipset。</p><p>上面已经有说到kube-proxy所生成的iptables规则的链，会有一篇专门的文章讲kube-proxy如何监听和更新规则的，暂时就说这么多。</p><h4 id=corednskube-dns>CoreDNS/Kube-DNS</h4><p>集群内域名解析就不说了，很简单。</p><p>这里梳理一下对集群外域名的请求流程是怎么样的。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>droot@python-server-65b886d59c-5gz2g:/app# cat /etc/resolv.conf
</span></span><span class=line><span class=cl>search net-test.svc.cluster.local svc.cluster.local cluster.local
</span></span><span class=line><span class=cl>nameserver 10.96.0.10
</span></span><span class=line><span class=cl>options ndots:5
</span></span></code></pre></td></tr></table></div></div><p>可以查看CoreDNS所用的配置，有个forward插件，具体用途在这 <a href=https://coredns.io/plugins/forward/>DoreDNS-plugin/forward</a>，其实就是将dns请求转发至上游dns。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@k8s-master01 ~<span class=o>]</span><span class=c1># kubectl get cm coredns -n kube-system -o yaml</span>
</span></span><span class=line><span class=cl>apiVersion: v1
</span></span><span class=line><span class=cl>data:
</span></span><span class=line><span class=cl>  Corefile: <span class=p>|</span>
</span></span><span class=line><span class=cl>    .:53 <span class=o>{</span>
</span></span><span class=line><span class=cl>        errors
</span></span><span class=line><span class=cl>        health <span class=o>{</span>
</span></span><span class=line><span class=cl>           lameduck 5s
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        ready
</span></span><span class=line><span class=cl>        kubernetes cluster.local in-addr.arpa ip6.arpa <span class=o>{</span>
</span></span><span class=line><span class=cl>           pods insecure
</span></span><span class=line><span class=cl>           fallthrough in-addr.arpa ip6.arpa
</span></span><span class=line><span class=cl>           ttl <span class=m>30</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        prometheus :9153
</span></span><span class=line><span class=cl>        <span class=c1>## 这里的文件就是宿主机的文件，个别系统该文件受systemd-resolved管理，无法直接改动</span>
</span></span><span class=line><span class=cl>        <span class=c1>## 可以通过coredns_forward_request_total{k8s_app=&#34;kube-dns&#34;}这个指标看到多少请求被转发至上游</span>
</span></span><span class=line><span class=cl>        forward . /etc/resolv.conf <span class=o>{</span>
</span></span><span class=line><span class=cl>           max_concurrent <span class=m>1000</span>
</span></span><span class=line><span class=cl>        <span class=o>}</span>
</span></span><span class=line><span class=cl>        cache <span class=m>30</span>
</span></span><span class=line><span class=cl>        loop
</span></span><span class=line><span class=cl>        reload
</span></span><span class=line><span class=cl>        loadbalance
</span></span><span class=line><span class=cl>    <span class=o>}</span>
</span></span><span class=line><span class=cl>kind: ConfigMap
</span></span><span class=line><span class=cl>metadata:
</span></span><span class=line><span class=cl>  name: coredns
</span></span><span class=line><span class=cl>  namespace: kube-system
</span></span><span class=line><span class=cl>  resourceVersion: <span class=s2>&#34;281&#34;</span>
</span></span><span class=line><span class=cl>  uid: bf0f0e56-fb2c-4392-9d42-1a55a127ecf2
</span></span></code></pre></td></tr></table></div></div><h2 id=四常见的非硬件的网络问题>四、常见的非硬件的网络问题</h2><p>暂不考虑南北向的外网访问集群这种情况，因为涉及CDN之类的复杂环境，所以只讨论东西向网络。</p><ol><li>域名访问超时、解析失效，时不时出现前面所说<ol><li>如果是外网域名，由本文3.2可知，集群内找不到域名会forward到宿主机，对齐集群服务器的<code>resolv.conf</code>文件。曾出现过部分服务器DNS配置更新滞后，导致部分第三方支付API请求不通的情况。</li><li>集群内域名解析慢，在Service配置正确的情况下，有可能CoreDNS的Pod负载过大，挖个坑会讨论<code>如何看Linux的网络负载监控</code></li></ol></li><li></li></ol><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=o>[</span>root@k8s-master01 ~<span class=o>]</span><span class=c1># ./calicoctl node status</span>
</span></span><span class=line><span class=cl>Calico process is running.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>IPv4 BGP status
</span></span><span class=line><span class=cl>+--------------+-------------------+-------+------------+-------------+
</span></span><span class=line><span class=cl><span class=p>|</span> PEER ADDRESS <span class=p>|</span>     PEER TYPE     <span class=p>|</span> STATE <span class=p>|</span>   SINCE    <span class=p>|</span>    INFO     <span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------+-------------------+-------+------------+-------------+
</span></span><span class=line><span class=cl><span class=p>|</span> 10.0.17.6    <span class=p>|</span> node-to-node mesh <span class=p>|</span> up    <span class=p>|</span> 2024-06-05 <span class=p>|</span> Established <span class=p>|</span>
</span></span><span class=line><span class=cl><span class=p>|</span> 10.0.17.7    <span class=p>|</span> node-to-node mesh <span class=p>|</span> up    <span class=p>|</span> 2024-06-05 <span class=p>|</span> Established <span class=p>|</span>
</span></span><span class=line><span class=cl>+--------------+-------------------+-------+------------+-------------+
</span></span></code></pre></td></tr></table></div></div></article><ul class=article-share><li><a class=resp-sharing-button__link href="https://facebook.com/sharer/sharer.php?u=/kubernetes%25E7%259A%2584%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E6%2580%25BB%25E7%25BB%2593%25E7%25BD%2591%25E7%25BB%259C%25E6%2595%2585%25E9%259A%259C%25E6%258E%2592%25E6%259F%25A5%25E6%25A0%25B8%25E5%25BF%2583%25E6%2580%259D%25E8%25B7%25AF/" target=_blank rel=noopener aria-label=Facebook><div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--medium"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><i class="fa-brands fa-facebook-f"></i></div>Facebook</div></a></li><li><a class=resp-sharing-button__link href="https://x.com/intent/tweet/?text=%e3%80%90%e6%b7%b1%e5%ba%a6%e8%a7%a3%e6%9e%90%e3%80%91%e8%af%a6%e7%bb%86%e6%a2%b3%e7%90%86Kubernetes%e7%9a%84%e7%bd%91%e7%bb%9c%e6%a8%a1%e5%9e%8b%ef%bc%8c%e6%80%bb%e7%bb%93%e7%bd%91%e7%bb%9c%e6%95%85%e9%9a%9c%e6%8e%92%e6%9f%a5%e6%a0%b8%e5%bf%83%e6%80%9d%e8%b7%af%20-%20%e7%bb%b4%e4%bf%ae%e5%8c%ba%e5%88%b7%e7%b4%ab&amp;url=/kubernetes%25E7%259A%2584%25E7%25BD%2591%25E7%25BB%259C%25E6%25A8%25A1%25E5%259E%258B%25E6%2580%25BB%25E7%25BB%2593%25E7%25BD%2591%25E7%25BB%259C%25E6%2595%2585%25E9%259A%259C%25E6%258E%2592%25E6%259F%25A5%25E6%25A0%25B8%25E5%25BF%2583%25E6%2580%259D%25E8%25B7%25AF/" target=_blank rel=noopener aria-label=Twitter><div class="resp-sharing-button resp-sharing-button--x resp-sharing-button--medium"><i class="fa-brands fa-x-twitter"></i></div></a></li></ul><ul class="pager article-pager"><li class="pager-newer pager-noitem">&lt; Newer</li><li class=pager-older><a href=/%E9%97%AE%E9%A2%98%E5%A4%A7%E6%8E%92%E6%9F%A5%E4%B8%80%E8%88%AC%E7%8E%AF%E5%A2%83%E7%9A%84%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/ data-toggle=tooltip data-placement=top title=【问题大排查】通用Linux环境的网络排障（部分包含容器环境）>Older ></a></li></ul></div><div class=site-footer><div class=copyright>© 2025 黄泽宏 | <a href=https://beian.miit.gov.cn/ target=_blank>粤ICP备2025417888号-1</a></div><ul class=site-footer-items><li class=site-footer-item-about><a href=/about/ title=About>About</a></li></ul><div class=powerdby>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://github.com/taikii/whiteplain>Whiteplain</a>
<script>fetch("https://ghtrk-pixel.fly.dev/goodtracker.png?from=hugo-footer-huangzehong_me&ts="+Date.now())</script></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-16F0MHER15"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-16F0MHER15",{anonymize_ip:!1})}</script></body></html>