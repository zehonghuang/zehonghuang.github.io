<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"><title>【问题大排查】通用Linux环境的网络排障（部分包含容器环境） - 维修区刷紫</title>
<meta property="og:title" content="【问题大排查】通用Linux环境的网络排障（部分包含容器环境） - 维修区刷紫"><meta name=twitter:title content="【问题大排查】通用Linux环境的网络排障（部分包含容器环境） - 维修区刷紫"><meta name=description content="
因为最近一段时间，一直在处理各种网路问题，所以痛定思痛从头梳理一般运维环境下的网络状况

网络不通（持续性）
这个情况没啥好说的，只要不是 DNS 问题，就是服务器挂掉或者端口被禁
端口监听挂掉
如果容器内的端口已经没有进程监听了，内核就会返回 Reset 包，客户端就会报错连接被拒绝，可以进容器 netns 检查下端口是否存活:


1


netstat -tunlp


iptables 规则问题
检查报文是否有命中丢弃报文的 iptables 规则:


1
2
3
4
5


iptables -t filter -nvL
iptables -t nat -nvL
iptables -t raw -nvL
iptables -t mangle -nvL
iptables-save


"><meta property="og:description" content="
因为最近一段时间，一直在处理各种网路问题，所以痛定思痛从头梳理一般运维环境下的网络状况

网络不通（持续性）
这个情况没啥好说的，只要不是 DNS 问题，就是服务器挂掉或者端口被禁
端口监听挂掉
如果容器内的端口已经没有进程监听了，内核就会返回 Reset 包，客户端就会报错连接被拒绝，可以进容器 netns 检查下端口是否存活:


1


netstat -tunlp


iptables 规则问题
检查报文是否有命中丢弃报文的 iptables 规则:


1
2
3
4
5


iptables -t filter -nvL
iptables -t nat -nvL
iptables -t raw -nvL
iptables -t mangle -nvL
iptables-save


"><meta name=twitter:description content="
因为最近一段时间，一直在处理各种网路问题，所以痛定思痛从头梳理一般运维环境下的网络状况

网络不通（持续性）
这个情况没啥好说的，只要不是 DNS 问题，就是服务器挂掉或者端口被禁
端口监听挂掉
如果容器内的端口已经没有进程监听了，内核就会返回 Reset 包，客户端就会报错连接被拒绝，可以进容器 netns 检查下端口是否存活:


1


netstat -tunlp


iptables  …"><meta name=author content="金汤力"><link rel=icon type=image/x-icon href=/images/favicon.ico><meta property="og:site_name" content="维修区刷紫"><meta property="og:url" content="/%E9%97%AE%E9%A2%98%E5%A4%A7%E6%8E%92%E6%9F%A5%E4%B8%80%E8%88%AC%E7%8E%AF%E5%A2%83%E7%9A%84%E7%BD%91%E7%BB%9C%E6%8E%92%E9%9A%9C/"><meta property="og:type" content="article"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.120.2"><script src=https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/Base64/1.3.0/base64.min.js integrity="sha512-IFxgh3q1bUsg/sL6qotMkJZTOvPyYSS6mRSSIVnJndN5j9vWcQ+oJyHkelIkRAOaKgdU1ibHJOs4HX15sPtZKw==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b5f7da576488071eb46ec9fe633fa64",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=/css/style.css media=all><link rel=stylesheet href=/css/style-dark.css media="all and (prefers-color-scheme: dark)"><link rel=stylesheet href=/css/syntax.css media=all><link rel=stylesheet href=/css/custom.css media=all><script src=/js/script.js></script><script src=/js/custom.js></script><script defer src=/fontawesome/all.min.js></script></head><body><header class=site-header><nav class=site-navi><h1 class=site-title><a href=/>维修区刷紫</a></h1><ul class=site-navi-items><li class=site-navi-item-archives><a href=/archives/ title=所有文章>所有文章</a></li><li class=site-navi-item-categories><a href=/categories/ title=类别>类别</a></li><li class=site-navi-item-about><a href=/about/ title=关于我>关于我</a></li></ul></nav></header><hr class=site-header-bottom><div class=main role=main><article class=article><h1 class=article-title>【问题大排查】通用Linux环境的网络排障（部分包含容器环境）</h1><hr class=article-title-bottom><ul class=article-meta><li class=article-meta-date><time>2022-07-26</time></li><li class=article-meta-categories><a href=/categories/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/><i class="fa-solid fa-folder"></i>
深度解析
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><aside class=toc><nav id=TableOfContents><ul><li><a href=#网络不通持续性>网络不通（持续性）</a><ul><li><a href=#端口监听挂掉>端口监听挂掉</a></li><li><a href=#iptables-规则问题>iptables 规则问题</a></li></ul></li><li><a href=#网络偶尔丢包>网络偶尔丢包</a><ul><li></li><li><a href=#arp-表爆满>arp 表爆满</a></li><li><a href=#mtu-不一致导致丢包>MTU 不一致导致丢包</a></li><li><a href=#qos-限流丢包>QoS 限流丢包</a></li><li><a href=#pps-限速对包>PPS 限速对包</a></li><li><a href=#连接队列满导致丢包>连接队列满导致丢包</a></li><li><a href=#源端口耗尽>源端口耗尽</a></li><li><a href=#tcp_tw_recycle-导致丢包>tcp_tw_recycle 导致丢包</a></li></ul></li></ul></nav></aside><blockquote><p>因为最近一段时间，一直在处理各种网路问题，所以痛定思痛从头梳理<strong>一般运维环境下的网络状况</strong></p></blockquote><h2 id=网络不通持续性>网络不通（持续性）</h2><p>这个情况没啥好说的，只要不是 DNS 问题，就是服务器挂掉或者端口被禁</p><h3 id=端口监听挂掉>端口监听挂掉</h3><p>如果容器内的端口已经没有进程监听了，内核就会返回 Reset 包，客户端就会报错连接被拒绝，可以进容器 netns 检查下端口是否存活:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>netstat -tunlp
</span></span></code></pre></td></tr></table></div></div><h3 id=iptables-规则问题>iptables 规则问题</h3><p>检查报文是否有命中丢弃报文的 iptables 规则:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>iptables -t filter -nvL
</span></span><span class=line><span class=cl>iptables -t nat -nvL
</span></span><span class=line><span class=cl>iptables -t raw -nvL
</span></span><span class=line><span class=cl>iptables -t mangle -nvL
</span></span><span class=line><span class=cl>iptables-save
</span></span></code></pre></td></tr></table></div></div><h2 id=网络偶尔丢包>网络偶尔丢包</h2><p>网络丢包一般现象就是<strong>偶尔不通或者速度很慢</strong>.</p><h4 id=高并发-nat-导致-conntrack-插入冲突>高并发 NAT 导致 conntrack 插入冲突</h4><p>如果高并发并且做了 NAT，比如使用了 ip-masq-agent，对集群外的网段或公网进行 SNAT，又或者集群内访问 Service 被做了 DNAT，
再加上高并发的话，内核就会高并发进行 NAT 和 conntrack 插入，当并发 NAT 后五元组冲突，最终插入的时候只有先插入的那个成功，另外冲突的就会插入失败，然后就丢包了。</p><p>可以通过 conntrack -S 确认，如果 insert_failed 计数在增加，说明有 conntrack 插入冲突。</p><p>看内核日志:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># demsg</span>
</span></span><span class=line><span class=cl>$ journalctl -k <span class=p>|</span> grep <span class=s2>&#34;nf_conntrack: table full&#34;</span>
</span></span><span class=line><span class=cl>nf_conntrack: nf_conntrack: table full, dropping packet
</span></span></code></pre></td></tr></table></div></div><p>若有以上报错，证明 conntrack 表满了，需要调大 conntrack 表:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sysctl -w net.netfilter.nf_conntrack_max<span class=o>=</span><span class=m>1000000</span>
</span></span></code></pre></td></tr></table></div></div><p>socket buffer 满导致丢包
<code>netstat -s | grep "buffer errors"</code>的计数统计在增加，说明流量较大，socket buffer 不够用，需要调大下 buffer 容量:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>net.ipv4.tcp_wmem <span class=o>=</span> <span class=m>4096</span>        <span class=m>16384</span>   <span class=m>4194304</span>
</span></span><span class=line><span class=cl>net.ipv4.tcp_rmem <span class=o>=</span> <span class=m>4096</span>        <span class=m>87380</span>   <span class=m>6291456</span>
</span></span><span class=line><span class=cl>net.ipv4.tcp_mem <span class=o>=</span> <span class=m>381462</span>       <span class=m>508616</span>  <span class=m>762924</span>
</span></span><span class=line><span class=cl>net.core.rmem_default <span class=o>=</span> <span class=m>8388608</span>
</span></span><span class=line><span class=cl>net.core.rmem_max <span class=o>=</span> <span class=m>26214400</span>
</span></span><span class=line><span class=cl>net.core.wmem_max <span class=o>=</span> <span class=m>26214400</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=arp-表爆满>arp 表爆满</h3><p>看内核日志:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># demsg</span>
</span></span><span class=line><span class=cl>$ journalctl -k <span class=p>|</span> grep <span class=s2>&#34;neighbor table overflow&#34;</span>
</span></span><span class=line><span class=cl>arp_cache: neighbor table overflow!
</span></span></code></pre></td></tr></table></div></div><p>若有以上报错，证明 arp 表满了，查看当前 arp 记录数:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ arp -an <span class=p>|</span> wc -l
</span></span><span class=line><span class=cl><span class=m>1335</span>
</span></span></code></pre></td></tr></table></div></div><p>查看 arp gc 阀值:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ sysctl -a <span class=p>|</span> grep gc_thresh
</span></span><span class=line><span class=cl><span class=c1>## 系统在 ARP 表中的条目数量低于该值时，垃圾回收不被触发，表示最小保持的 ARP 条目数</span>
</span></span><span class=line><span class=cl>net.ipv4.neigh.default.gc_thresh1 <span class=o>=</span> <span class=m>128</span>
</span></span><span class=line><span class=cl><span class=c1>## ARP 表中的条目数超过该值时，系统会尝试回收一些条目，这是回收的软阈值</span>
</span></span><span class=line><span class=cl>net.ipv4.neigh.default.gc_thresh2 <span class=o>=</span> <span class=m>512</span>
</span></span><span class=line><span class=cl><span class=c1>## ARP 表的最大容量，超过此值后，新的 ARP 条目将无法被添加</span>
</span></span><span class=line><span class=cl>net.ipv4.neigh.default.gc_thresh3 <span class=o>=</span> <span class=m>1024</span>
</span></span></code></pre></td></tr></table></div></div><p>调大 arp 表:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>sysctl -w net.ipv4.neigh.default.gc_thresh1<span class=o>=</span><span class=m>80000</span>
</span></span><span class=line><span class=cl>sysctl -w net.ipv4.neigh.default.gc_thresh2<span class=o>=</span><span class=m>90000</span>
</span></span><span class=line><span class=cl>sysctl -w net.ipv4.neigh.default.gc_thresh3<span class=o>=</span><span class=m>100000</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p>这个情况极大可能出现在kubernetes集群里的某些服务，例如对中大型集群(1000个节点)内做巡检的Pod，如果有类似情况建议在个别节点上调大arp</p><p>然后给对应的Node打上标签 <code>kubectl label node host1 arp_cache=large</code></p><p>然后用 nodeSelector 或 nodeAffnity 让这部分需要内核有大 arp_cache 容量的 Pod 只调度到这部分节点，推荐使用 nodeAffnity，yaml 示例:</p></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>affinity</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>nodeAffinity</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>requiredDuringSchedulingIgnoredDuringExecution</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>nodeSelectorTerms</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>matchExpressions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>arp_cache</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=l>In</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span><span class=nt>values</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>                </span>- <span class=l>large</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><h3 id=mtu-不一致导致丢包>MTU 不一致导致丢包</h3><p>如果容器内网卡 MTU 比另一端宿主机内的网卡 MTU 不一致(通常是 CNI 插件问题)，数据包就可能被截断导致一些数据丢失:</p><ol><li>如果容器内的 MTU 更大，发出去的包如果超过 MTU 可能就被丢弃了(通常节点内核不会像交换机那样严谨会分片发送)。</li><li>同样的，如果容器内的 MTU 更小，进来的包如果超过 MTU 可能就被丢弃。</li></ol><blockquote><p>tcp 协商 mss 的时候，主要看的是进程通信两端网卡的 MTU。</p></blockquote><p>MTU 大小可以通过<code>ip address show</code>或<code>ifconfig</code>来确认。</p><h3 id=qos-限流丢包>QoS 限流丢包</h3><p>在云厂商的云主机环境，有可能会在底层会对某些包进行 QoS 限流，比如为了防止公共 DNS 被 DDoS 攻击，
限制 UDP 53 端口的包的流量，超过特定速度阈值就丢包，导致部分 DNS 请求丢包而超时。</p><h3 id=pps-限速对包>PPS 限速对包</h3><p>网卡的速度始终是有上限的，在云环境下，不同机型不同规格的云主机的 PPS 上限也不一样，超过阈值后就不保证能正常转发，可能就丢包了。</p><h3 id=连接队列满导致丢包>连接队列满导致丢包</h3><p>对于 TCP 连接，三次握手建立连接，没建连成功前存储在半连接队列，建连成功但还没被应用层 accept 之前，存储在全连接队列。队列大小是有上限的，如果慢了就会丢包：</p><ul><li>如果并发太高或机器负载过高，半连接队列可能会满，新来的 SYN 建连包会被丢包。</li><li>如果应用层 accept 连接过慢，会导致全连接队列堆积，满了就会丢包，通常是并发高、机器负载高或应用夯死等原因。</li></ul><p>查看丢包统计:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>netstat -s <span class=p>|</span> grep -E <span class=s1>&#39;drop|overflow&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$ cat /proc/net/netstat <span class=p>|</span> awk <span class=s1>&#39;/TcpExt/ { print $21,$22 }&#39;</span>
</span></span><span class=line><span class=cl>ListenOverlows ListenDrops
</span></span><span class=line><span class=cl><span class=m>20168</span> <span class=m>20168</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p>不同内核版本的列号可能有差别</p></blockquote><p>如果有现场，还可以观察全连接队列阻塞情况 (<code>Rec-Q</code>):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>ss -lnt
</span></span></code></pre></td></tr></table></div></div><p>通过以下内核参数可以调整队列大小 (namespace隔离):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>net.ipv4.tcp_max_syn_backlog <span class=o>=</span> <span class=m>8096</span> <span class=c1># 调整半连接队列上限</span>
</span></span><span class=line><span class=cl>net.core.somaxconn <span class=o>=</span> <span class=m>32768</span> <span class=c1># 调整全连接队列上限</span>
</span></span></code></pre></td></tr></table></div></div><p>需要注意的是，<code>somaxconn</code>只是调整了队列最大的上限，但实际队列大小是应用在<code>listen</code>时传入的<code>backlog</code>大小，
大多编程语言默认会自动读取<code>somaxconn</code>的值作为<code>listen</code>系统调用的<code>backlog</code>参数的大小。</p><p>如果是用nginx，<code>backlog</code>的值需要在<code>nginx.conf</code>配置中显示指定，否则会用它自己的默认值<strong>511</strong>。</p><h3 id=源端口耗尽>源端口耗尽</h3><p>当作为 client 发请求，或外部流量从NodePort进来时进行SNAT，会从当前 netns 中选择一个端口作为源端口，
端口范围由<code>net.ipv4.ip_local_port_range</code>这个内核参数决定，如果并发量大，就可能导致源端口耗尽，从而丢包。</p><h3 id=tcp_tw_recycle-导致丢包>tcp_tw_recycle 导致丢包</h3><p>在低版本内核中(比如 3.10)，支持使用 tcp_tw_recycle 内核参数来开启 TIME_WAIT 的快速回收，
但如果 client 也开启了 timestamp (一般默认开启)，同时也就会导致在 NAT 环境丢包，
甚至没有 NAT 时，稍微高并发一点，也会导致 PAWS 校验失败，导致丢包:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 看 SYN 丢包是否全都是 PAWS 校验失败</span>
</span></span><span class=line><span class=cl>$ cat /proc/net/netstat <span class=p>|</span> grep TcpE<span class=p>|</span> awk <span class=s1>&#39;{print $15, $22}&#39;</span>
</span></span><span class=line><span class=cl>PAWSPassive ListenDrops
</span></span><span class=line><span class=cl><span class=m>96305</span> <span class=m>96305</span>
</span></span><span class=line><span class=cl><span class=c1>## PAWSPassive PAWS 是为防止序列号回绕而使用的保护机制，如果包的时间戳有问题，PAWS 可能会导致包被丢弃</span>
</span></span><span class=line><span class=cl><span class=c1>## ListenDrops 监听队列中的连接因队列已满而被丢弃的次数</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><p>TCP协议的PAWS机制可自行百度</p></blockquote></article><ul class=article-share><li><a class=resp-sharing-button__link href="https://facebook.com/sharer/sharer.php?u=/%25E9%2597%25AE%25E9%25A2%2598%25E5%25A4%25A7%25E6%258E%2592%25E6%259F%25A5%25E4%25B8%2580%25E8%2588%25AC%25E7%258E%25AF%25E5%25A2%2583%25E7%259A%2584%25E7%25BD%2591%25E7%25BB%259C%25E6%258E%2592%25E9%259A%259C/" target=_blank rel=noopener aria-label=Facebook><div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--medium"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><i class="fa-brands fa-facebook-f"></i></div>Facebook</div></a></li><li><a class=resp-sharing-button__link href="https://x.com/intent/tweet/?text=%e3%80%90%e9%97%ae%e9%a2%98%e5%a4%a7%e6%8e%92%e6%9f%a5%e3%80%91%e9%80%9a%e7%94%a8Linux%e7%8e%af%e5%a2%83%e7%9a%84%e7%bd%91%e7%bb%9c%e6%8e%92%e9%9a%9c%ef%bc%88%e9%83%a8%e5%88%86%e5%8c%85%e5%90%ab%e5%ae%b9%e5%99%a8%e7%8e%af%e5%a2%83%ef%bc%89%20-%20%e7%bb%b4%e4%bf%ae%e5%8c%ba%e5%88%b7%e7%b4%ab&amp;url=/%25E9%2597%25AE%25E9%25A2%2598%25E5%25A4%25A7%25E6%258E%2592%25E6%259F%25A5%25E4%25B8%2580%25E8%2588%25AC%25E7%258E%25AF%25E5%25A2%2583%25E7%259A%2584%25E7%25BD%2591%25E7%25BB%259C%25E6%258E%2592%25E9%259A%259C/" target=_blank rel=noopener aria-label=Twitter><div class="resp-sharing-button resp-sharing-button--x resp-sharing-button--medium"><i class="fa-brands fa-x-twitter"></i></div></a></li></ul><ul class="pager article-pager"><li class=pager-newer><a href=/kubernetes%E7%9A%84%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%80%BB%E7%BB%93%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF/ data-toggle=tooltip data-placement=top title=【深度解析】详细梳理Kubernetes的网络模型，总结网络故障排查核心思路>&lt; Newer</a></li><li class=pager-older><a href=/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98k8s%E9%80%80%E5%87%BA%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%E9%97%AE%E9%A2%98/ data-toggle=tooltip data-placement=top title=【生产问题】K8s退出信号处理和僵尸进程问题>Older ></a></li></ul></div><div class=site-footer><div class=copyright>© 2025 黄泽宏 | <a href=https://beian.miit.gov.cn/ target=_blank>粤ICP备2025417888号-1</a></div><ul class=site-footer-items><li class=site-footer-item-about><a href=/about/ title=About>About</a></li></ul><div class=powerdby>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://github.com/taikii/whiteplain>Whiteplain</a>
<script>fetch("https://ghtrk-pixel.fly.dev/goodtracker.png?from=hugo-footer-huangzehong_me&ts="+Date.now())</script></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-16F0MHER15"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-16F0MHER15",{anonymize_ip:!1})}</script></body></html>