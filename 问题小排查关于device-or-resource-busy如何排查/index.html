<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1"><title>【问题小排查】关于device or Resource Busy如何排查 - 维修区刷紫</title>
<meta property="og:title" content="【问题小排查】关于device or Resource Busy如何排查 - 维修区刷紫"><meta name=twitter:title content="【问题小排查】关于device or Resource Busy如何排查 - 维修区刷紫"><meta name=description content="背景 在 kubernetes 环境中，可能会遇到因目录被占用导致 pod 一直 terminating:
1 Aug 27 15:52:22 VM-244-70-centos kubelet[906978]: E0827 15:52:22.816125 906978 nestedpendingoperations.go:270] Operation for &#34;\&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34; (\&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;)&#34; failed. No retries permitted until 2021-08-27 15:54:24.816098325 +0800 CST m=+108994.575932846 (durationBeforeRetry 2m2s). Error: &#34;UnmountVolume.TearDown failed for volume \&#34;default-token-fltdk\&#34; (UniqueName: \&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34;) pod \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34; (UID: \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;) : unlinkat /var/lib/kubelet/pods/b45f3af4-3574-472e-b263-c2b71c3b2ea0/volumes/kubernetes.io~secret/default-token-fltdk: device or resource busy&#34; 本文记录下排查方法。
找出目录被谁占用的 看下目录哪个进程 mount 了:
1 2 $ find /proc/*/mounts -exec grep /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm {} + 2>/dev/null /proc/6076/mounts:tmpfs /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm tmpfs rw,relatime 0 0 根据找出的进程号，看看是谁干的:"><meta property="og:description" content="背景 在 kubernetes 环境中，可能会遇到因目录被占用导致 pod 一直 terminating:
1 Aug 27 15:52:22 VM-244-70-centos kubelet[906978]: E0827 15:52:22.816125 906978 nestedpendingoperations.go:270] Operation for &#34;\&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34; (\&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;)&#34; failed. No retries permitted until 2021-08-27 15:54:24.816098325 +0800 CST m=+108994.575932846 (durationBeforeRetry 2m2s). Error: &#34;UnmountVolume.TearDown failed for volume \&#34;default-token-fltdk\&#34; (UniqueName: \&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34;) pod \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34; (UID: \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;) : unlinkat /var/lib/kubelet/pods/b45f3af4-3574-472e-b263-c2b71c3b2ea0/volumes/kubernetes.io~secret/default-token-fltdk: device or resource busy&#34; 本文记录下排查方法。
找出目录被谁占用的 看下目录哪个进程 mount 了:
1 2 $ find /proc/*/mounts -exec grep /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm {} + 2>/dev/null /proc/6076/mounts:tmpfs /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm tmpfs rw,relatime 0 0 根据找出的进程号，看看是谁干的:"><meta name=twitter:description content="背景 在 kubernetes 环境中，可能会遇到因目录被占用导致 pod 一直 terminating:
1 Aug 27 15:52:22 VM-244-70-centos kubelet[906978]: E0827 15:52:22.816125 906978 nestedpendingoperations.go:270] Operation for …"><meta name=author content="金汤力"><link rel=icon type=image/x-icon href=/images/favicon.ico><meta property="og:site_name" content="维修区刷紫"><meta property="og:url" content="/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E5%85%B3%E4%BA%8Edevice-or-resource-busy%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5/"><meta property="og:type" content="article"><meta name=twitter:card content="summary"><meta name=generator content="Hugo 0.120.2"><script src=https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/Base64/1.3.0/base64.min.js integrity="sha512-IFxgh3q1bUsg/sL6qotMkJZTOvPyYSS6mRSSIVnJndN5j9vWcQ+oJyHkelIkRAOaKgdU1ibHJOs4HX15sPtZKw==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b5f7da576488071eb46ec9fe633fa64",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><link rel=stylesheet href=/css/style.css media=all><link rel=stylesheet href=/css/style-dark.css media="all and (prefers-color-scheme: dark)"><link rel=stylesheet href=/css/syntax.css media=all><link rel=stylesheet href=/css/custom.css media=all><script src=/js/script.js></script><script src=/js/custom.js></script><script defer src=/fontawesome/all.min.js></script></head><body><header class=site-header><nav class=site-navi><h1 class=site-title><a href=/>维修区刷紫</a></h1><ul class=site-navi-items><li class=site-navi-item-archives><a href=/archives/ title=所有文章>所有文章</a></li><li class=site-navi-item-categories><a href=/categories/ title=类别>类别</a></li><li class=site-navi-item-about><a href=/about/ title=关于我>关于我</a></li></ul></nav></header><hr class=site-header-bottom><div class=main role=main><article class=article><h1 class=article-title>【问题小排查】关于device or Resource Busy如何排查</h1><hr class=article-title-bottom><ul class=article-meta><li class=article-meta-date><time>2021-07-09</time></li><li class=article-meta-categories><a href=/categories/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5/><i class="fa-solid fa-folder"></i>
问题小排查
</a>&nbsp;</li><li class=article-meta-categories><a href=/categories/kubernetes/><i class="fa-solid fa-folder"></i>
Kubernetes
</a>&nbsp;</li></ul><h3 id=背景>背景</h3><p>在 kubernetes 环境中，可能会遇到因目录被占用导致 pod 一直 terminating:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>Aug <span class=m>27</span> 15:52:22 VM-244-70-centos kubelet<span class=o>[</span>906978<span class=o>]</span>: E0827 15:52:22.816125  <span class=m>906978</span> nestedpendingoperations.go:270<span class=o>]</span> Operation <span class=k>for</span> <span class=s2>&#34;\&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34; (\&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;)&#34;</span> failed. No retries permitted <span class=k>until</span> 2021-08-27 15:54:24.816098325 +0800 CST <span class=nv>m</span><span class=o>=</span>+108994.575932846 <span class=o>(</span>durationBeforeRetry 2m2s<span class=o>)</span>. Error: <span class=s2>&#34;UnmountVolume.TearDown failed for volume \&#34;default-token-fltdk\&#34; (UniqueName: \&#34;kubernetes.io/secret/b45f3af4-3574-472e-b263-c2b71c3b2ea0-default-token-fltdk\&#34;) pod \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34; (UID: \&#34;b45f3af4-3574-472e-b263-c2b71c3b2ea0\&#34;) : unlinkat /var/lib/kubelet/pods/b45f3af4-3574-472e-b263-c2b71c3b2ea0/volumes/kubernetes.io~secret/default-token-fltdk: device or resource busy&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>本文记录下排查方法。</p><h3 id=找出目录被谁占用的>找出目录被谁占用的</h3><p>看下目录哪个进程 mount 了:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ find /proc/*/mounts -exec grep /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm <span class=o>{}</span> + 2&gt;/dev/null
</span></span><span class=line><span class=cl>/proc/6076/mounts:tmpfs /var/lib/kubelet/pods/0104ab85-d0ea-4ac5-a5f9-5bdd12cca589/volumes/kubernetes.io~secret/kube-proxy-token-nvthm tmpfs rw,relatime <span class=m>0</span> <span class=m>0</span>
</span></span></code></pre></td></tr></table></div></div><p>根据找出的进程号，看看是谁干的:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ ps -ef <span class=p>|</span> grep -v grep <span class=p>|</span> grep <span class=m>6076</span>
</span></span><span class=line><span class=cl>root        <span class=m>6076</span>    <span class=m>6057</span>  <span class=m>0</span> Aug26 ?        00:01:54 /usr/local/loglistener/bin loglistener -c /usr/local/loglistener/etc/loglistener.conf
</span></span></code></pre></td></tr></table></div></div><p>看下完整的进程树:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ pstree -apnhs <span class=m>6076</span>
</span></span><span class=line><span class=cl>systemd,1 --switched-root --system --deserialize <span class=m>22</span>
</span></span><span class=line><span class=cl>  └─dockerd,1809 --config-file<span class=o>=</span>/etc/docker/daemon.json
</span></span><span class=line><span class=cl>      └─docker-containe,1868 --config /var/run/docker/containerd/containerd.toml
</span></span><span class=line><span class=cl>          └─docker-containe,6057 -namespace moby -workdir /data/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9a8457284ce7078ef838e78b79c87c5b27d8a6682597b44ba7a74d7ec6965365 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root ...
</span></span><span class=line><span class=cl>              └─loglistener,6076 loglistener -c /usr/local/loglistener/etc/loglistener.conf
</span></span><span class=line><span class=cl>                  ├─<span class=o>{</span>loglistener<span class=o>}</span>,6108
</span></span><span class=line><span class=cl>                  ├─<span class=o>{</span>loglistener<span class=o>}</span>,6109
</span></span><span class=line><span class=cl>                  ├─<span class=o>{</span>loglistener<span class=o>}</span>,6110
</span></span><span class=line><span class=cl>                  ├─<span class=o>{</span>loglistener<span class=o>}</span>,6111
</span></span><span class=line><span class=cl>                  └─<span class=o>{</span>loglistener<span class=o>}</span>,6112
</span></span></code></pre></td></tr></table></div></div><h3 id=反查-pod>反查 Pod</h3><p>如果占住这个目录的进程也是通过 Kubernetes 部署的，我们可以反查出是哪个 Pod 干的。</p><p>通过 nsenter 进入容器的 netns，查看 ip 地址，反查出是哪个 pod:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ nsenter -n -t <span class=m>6076</span>
</span></span><span class=line><span class=cl>$ ip a 
</span></span><span class=line><span class=cl>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span class=m>65536</span> qdisc noqueue state UNKNOWN group default 
</span></span><span class=line><span class=cl>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span><span class=line><span class=cl>    inet 127.0.0.1/8 scope host lo
</span></span><span class=line><span class=cl>       valid_lft forever preferred_lft forever
</span></span><span class=line><span class=cl>    inet6 ::1/128 scope host 
</span></span><span class=line><span class=cl>       valid_lft forever preferred_lft forever
</span></span><span class=line><span class=cl>2: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class=m>1500</span> qdisc mq state UP group default qlen <span class=m>10000</span>
</span></span><span class=line><span class=cl>    link/ether 52:54:00:ca:89:c0 brd ff:ff:ff:ff:ff:ff
</span></span><span class=line><span class=cl>    inet 192.168.244.70/24 brd 192.168.244.255 scope global eth1
</span></span><span class=line><span class=cl>       valid_lft forever preferred_lft forever
</span></span><span class=line><span class=cl>    inet6 fe80::5054:ff:feca:89c0/64 scope link 
</span></span><span class=line><span class=cl>       valid_lft forever preferred_lft forever
</span></span><span class=line><span class=cl>$ kubectl get pod -o wide -A <span class=p>|</span> grep 192.168.244.70
</span></span><span class=line><span class=cl>log-agent-24nn6                                      2/2     Running            <span class=m>0</span>          84d     192.168.244.70    10.10.10.22    &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></td></tr></table></div></div><p>如果 pod 是 hostNetwork 的，无法通过 ip 来分辨出是哪个 pod，可以提取进程树中出现的容器 id 前几位，然后查出容器名:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>$ docker ps <span class=p>|</span> grep 9a8457284c
</span></span><span class=line><span class=cl>9a8457284ce7        imroc/loglistener     <span class=s2>&#34;/usr/local/logliste…&#34;</span>   <span class=m>34</span> hours ago        Up <span class=m>34</span> hours                             k8s_loglistener_log-agent-wd2rp_kube-system_b0dcfe14-1619-43b5-a158-1e2063696138_1
</span></span></code></pre></td></tr></table></div></div><p>Kubernetes 的容器名就可以看出该容器属于哪个 pod。</p></article><ul class=article-share><li><a class=resp-sharing-button__link href="https://facebook.com/sharer/sharer.php?u=/%25E9%2597%25AE%25E9%25A2%2598%25E5%25B0%258F%25E6%258E%2592%25E6%259F%25A5%25E5%2585%25B3%25E4%25BA%258Edevice-or-resource-busy%25E5%25A6%2582%25E4%25BD%2595%25E6%258E%2592%25E6%259F%25A5/" target=_blank rel=noopener aria-label=Facebook><div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--medium"><div aria-hidden=true class="resp-sharing-button__icon resp-sharing-button__icon--solid"><i class="fa-brands fa-facebook-f"></i></div>Facebook</div></a></li><li><a class=resp-sharing-button__link href="https://x.com/intent/tweet/?text=%e3%80%90%e9%97%ae%e9%a2%98%e5%b0%8f%e6%8e%92%e6%9f%a5%e3%80%91%e5%85%b3%e4%ba%8edevice%20or%20Resource%20Busy%e5%a6%82%e4%bd%95%e6%8e%92%e6%9f%a5%20-%20%e7%bb%b4%e4%bf%ae%e5%8c%ba%e5%88%b7%e7%b4%ab&amp;url=/%25E9%2597%25AE%25E9%25A2%2598%25E5%25B0%258F%25E6%258E%2592%25E6%259F%25A5%25E5%2585%25B3%25E4%25BA%258Edevice-or-resource-busy%25E5%25A6%2582%25E4%25BD%2595%25E6%258E%2592%25E6%259F%25A5/" target=_blank rel=noopener aria-label=Twitter><div class="resp-sharing-button resp-sharing-button--x resp-sharing-button--medium"><i class="fa-brands fa-x-twitter"></i></div></a></li></ul><ul class="pager article-pager"><li class=pager-newer><a href=/%E5%85%AC%E5%8F%B8%E5%88%86%E4%BA%AB%E5%AD%A6%E4%B9%A0%E5%AE%B9%E5%99%A8%E7%A3%81%E7%9B%98%E5%8D%A0%E6%BB%A1%E5%AF%BC%E8%87%B4cpu%E9%A3%99%E9%AB%98/ data-toggle=tooltip data-placement=top title=【公司分享学习】容器磁盘占满导致CPU飙高>&lt; Newer</a></li><li class=pager-older><a href=/%E9%97%AE%E9%A2%98%E5%B0%8F%E6%8E%92%E6%9F%A5%E9%92%88%E5%AF%B9containerd-v1.4.3%E6%8B%89%E5%8F%96%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98/ data-toggle=tooltip data-placement=top title="【问题小排查】针对containerd V1.4.3拉取镜像的问题">Older ></a></li></ul></div><div class=site-footer><div class=copyright>© 2025 黄泽宏 | <a href=https://beian.miit.gov.cn/ target=_blank>粤ICP备2025417888号-1</a></div><ul class=site-footer-items><li class=site-footer-item-about><a href=/about/ title=About>About</a></li></ul><div class=powerdby>Powered by <a href=https://gohugo.io/>Hugo</a> and <a href=https://github.com/taikii/whiteplain>Whiteplain</a>
<script>fetch("https://ghtrk-pixel.fly.dev/goodtracker.png?from=hugo-footer-huangzehong_me&ts="+Date.now())</script></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=G-16F0MHER15"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-16F0MHER15",{anonymize_ip:!1})}</script></body></html>